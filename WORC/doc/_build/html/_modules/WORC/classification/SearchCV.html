

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>WORC.classification.SearchCV &mdash; WORC 3.1.2 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> WORC
          

          
          </a>

          
            
            
              <div class="version">
                3.1.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../static/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/quick_start.html">Quick start guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/user_manual.html">User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/file_description.html">Resource File Formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/changelog.html">Changelog</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../autogen/WORC.html">WORC Package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">WORC</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>WORC.classification.SearchCV</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for WORC.classification.SearchCV</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>

<span class="c1"># Copyright 2016-2019 Biomedical Imaging Group Rotterdam, Departments of</span>
<span class="c1"># Medical Informatics and Radiology, Erasmus MC, Rotterdam, The Netherlands</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>


<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">is_classifier</span><span class="p">,</span> <span class="n">clone</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">MetaEstimatorMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">NotFittedError</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.metaestimators</span> <span class="kn">import</span> <span class="n">if_delegate_has_method</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">indexable</span><span class="p">,</span> <span class="n">check_is_fitted</span>
<span class="kn">from</span> <span class="nn">WORC.classification.metrics</span> <span class="kn">import</span> <span class="n">check_scoring</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection._split</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">rankdata</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">six</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.fixes</span> <span class="kn">import</span> <span class="n">MaskedArray</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection._search</span> <span class="kn">import</span> <span class="n">ParameterSampler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection._search</span> <span class="kn">import</span> <span class="n">ParameterGrid</span><span class="p">,</span> <span class="n">_check_param_grid</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Sized</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">fastr</span>
<span class="kn">from</span> <span class="nn">fastr.api</span> <span class="kn">import</span> <span class="n">ResourceLimit</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="nn">WORC.classification.fitandscore</span> <span class="kn">import</span> <span class="n">fit_and_score</span><span class="p">,</span> <span class="n">replacenan</span>
<span class="kn">from</span> <span class="nn">WORC.classification.fitandscore</span> <span class="kn">import</span> <span class="n">delete_nonestimator_parameters</span>
<span class="kn">import</span> <span class="nn">WORC.addexceptions</span> <span class="k">as</span> <span class="nn">WORCexceptions</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">islice</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.multiclass</span> <span class="kn">import</span> <span class="n">OneVsRestClassifier</span>
<span class="kn">from</span> <span class="nn">WORC.classification.estimators</span> <span class="kn">import</span> <span class="n">RankedSVM</span>
<span class="kn">from</span> <span class="nn">WORC.classification</span> <span class="kn">import</span> <span class="n">construct_classifier</span> <span class="k">as</span> <span class="n">cc</span>


<div class="viewcode-block" id="rms_score"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.rms_score">[docs]</a><span class="k">def</span> <span class="nf">rms_score</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">prediction</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Root-mean-square-error metric&#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span></div>


<div class="viewcode-block" id="sar_score"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.sar_score">[docs]</a><span class="k">def</span> <span class="nf">sar_score</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">prediction</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; SAR metric from Caruana et al. 2004&#39;&#39;&#39;</span>

    <span class="n">ROC</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
    <span class="c1"># Convert score to binaries first</span>
    <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">prediction</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">prediction</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">prediction</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prediction</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">ACC</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
    <span class="n">RMS</span> <span class="o">=</span> <span class="n">rms_score</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
    <span class="n">SAR</span> <span class="o">=</span> <span class="p">(</span><span class="n">ACC</span> <span class="o">+</span> <span class="n">ROC</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">RMS</span><span class="p">))</span><span class="o">/</span><span class="mi">3</span>
    <span class="k">return</span> <span class="n">SAR</span></div>


<div class="viewcode-block" id="chunksdict"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.chunksdict">[docs]</a><span class="k">def</span> <span class="nf">chunksdict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Split a dictionary in equal parts of certain slice&#39;&#39;&#39;</span>
    <span class="n">it</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">SIZE</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">islice</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">SIZE</span><span class="p">)}</span></div>


<div class="viewcode-block" id="chunks"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.chunks">[docs]</a><span class="k">def</span> <span class="nf">chunks</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Yield successive n-sized chunks from l.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">l</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">]</span></div>


<div class="viewcode-block" id="Ensemble"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.Ensemble">[docs]</a><span class="k">class</span> <span class="nc">Ensemble</span><span class="p">(</span><span class="n">six</span><span class="o">.</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ABCMeta</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">,</span>
                                  <span class="n">MetaEstimatorMixin</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;Ensemble of BaseSearchCV Estimators.&quot;&quot;&quot;</span>
    <span class="c1"># @abstractmethod</span>
<div class="viewcode-block" id="Ensemble.__init__"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.Ensemble.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimators</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">estimators</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;You supplied an empty list of estimators: No ensemble creation possible.&#39;</span>
            <span class="k">raise</span> <span class="n">WORCexceptions</span><span class="o">.</span><span class="n">WORCValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span> <span class="o">=</span> <span class="n">estimators</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">estimators</span><span class="p">)</span></div>

<div class="viewcode-block" id="Ensemble.predict"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.Ensemble.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

        <span class="c1"># Check if we are dealing with multilabel</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">nlabels</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nlabels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span> <span class="o">==</span> <span class="n">OneVsRestClassifier</span><span class="p">:</span>
            <span class="n">multilabel</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">nlabels</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">multilabel</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">multilabel</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">multilabel</span><span class="p">:</span>
            <span class="c1"># Multilabel</span>
            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">nlabels</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="s1">&#39;predict_proba&#39;</span><span class="p">):</span>
                    <span class="c1"># BUG: SVM kernel can be wrong type</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">):</span>
                        <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
                    <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="c1"># Replace NAN if they are there</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">outcome</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WARNING] Predictions contain NaN, removing those rows.&#39;</span><span class="p">)</span>
                <span class="n">outcome</span> <span class="o">=</span> <span class="n">outcome</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">outcome</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

            <span class="c1"># NOTE: Binarize specifically for multiclass</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">outcome</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outcome</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span>
                <span class="n">outcome</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">outcome</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">outcome</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Singlelabel</span>
            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
            <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="s1">&#39;predict_proba&#39;</span><span class="p">):</span>
                    <span class="c1"># BUG: SVM kernel can be wrong type</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">):</span>
                        <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
                    <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="c1"># Replace NAN if they are there</span>
            <span class="n">outcome</span> <span class="o">=</span> <span class="n">outcome</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">outcome</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

            <span class="c1"># Binarize</span>
            <span class="n">isclassifier</span> <span class="o">=</span> <span class="n">is_classifier</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">isclassifier</span><span class="p">:</span>
                <span class="n">outcome</span><span class="p">[</span><span class="n">outcome</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">outcome</span><span class="p">[</span><span class="n">outcome</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">outcome</span></div>

<div class="viewcode-block" id="Ensemble.predict_proba"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.Ensemble.predict_proba">[docs]</a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict_proba on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict_proba``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;predict_proba&#39;</span><span class="p">)</span>

        <span class="c1"># Check if we are dealing with multilabel</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">nlabels</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nlabels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span> <span class="o">==</span> <span class="n">OneVsRestClassifier</span><span class="p">:</span>
            <span class="n">multilabel</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">nlabels</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">multilabel</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">multilabel</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">multilabel</span><span class="p">:</span>
            <span class="c1"># Multilabel</span>
            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">nlabels</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="s1">&#39;predict_proba&#39;</span><span class="p">):</span>
                    <span class="c1"># BUG: SVM kernel can be wrong type</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">):</span>
                        <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
                    <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="c1"># Replace NAN if they are there</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">outcome</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WARNING] Predictions contain NaN, removing those rows.&#39;</span><span class="p">)</span>
                <span class="n">outcome</span> <span class="o">=</span> <span class="n">outcome</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">outcome</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Single label</span>
            <span class="c1"># For probabilities, we get both a class0 and a class1 score</span>
            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
            <span class="n">outcome_class1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
            <span class="n">outcome_class2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
            <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
                <span class="c1"># BUG: SVM kernel can be wrong type</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">):</span>
                    <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
                <span class="n">outcome_class1</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="n">outcome_class2</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

            <span class="n">outcome</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome_class1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
            <span class="n">outcome</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome_class2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">outcome</span></div>

<div class="viewcode-block" id="Ensemble.predict_log_proba"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.Ensemble.predict_log_proba">[docs]</a>    <span class="k">def</span> <span class="nf">predict_log_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict_log_proba on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict_log_proba``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;predict_log_proba&#39;</span><span class="p">)</span>

        <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
            <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">predict_log_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">outcome</span></div>

<div class="viewcode-block" id="Ensemble.decision_function"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.Ensemble.decision_function">[docs]</a>    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call decision_function on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``decision_function``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;decision_function&#39;</span><span class="p">)</span>

        <span class="c1"># NOTE: Check if we are dealing with multilabel</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span> <span class="o">==</span> <span class="n">OneVsRestClassifier</span><span class="p">:</span>
            <span class="c1"># Multilabel</span>
            <span class="n">nlabels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">nlabels</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
                <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Singlelabel</span>
            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
            <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
                <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">outcome</span></div>

<div class="viewcode-block" id="Ensemble.transform"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.Ensemble.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call transform on the estimator with the best found parameters.</span>

<span class="sd">        Only available if the underlying estimator supports ``transform`` and</span>
<span class="sd">        ``refit=True``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;transform&#39;</span><span class="p">)</span>

        <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
            <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">outcome</span></div>

<div class="viewcode-block" id="Ensemble.inverse_transform"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.Ensemble.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xt</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call inverse_transform on the estimator with the best found params.</span>

<span class="sd">        Only available if the underlying estimator implements</span>
<span class="sd">        ``inverse_transform`` and ``refit=True``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        Xt : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;inverse_transform&#39;</span><span class="p">)</span>

        <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">Xt</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">):</span>
            <span class="n">outcome</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>

        <span class="n">outcome</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">outcome</span></div></div>


<div class="viewcode-block" id="BaseSearchCV"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV">[docs]</a><span class="k">class</span> <span class="nc">BaseSearchCV</span><span class="p">(</span><span class="n">six</span><span class="o">.</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ABCMeta</span><span class="p">,</span> <span class="n">BaseEstimator</span><span class="p">,</span>
                                      <span class="n">MetaEstimatorMixin</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;Base class for hyper parameter search with cross-validation.&quot;&quot;&quot;</span>
<div class="viewcode-block" id="BaseSearchCV.__init__"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.__init__">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="p">{},</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;2*n_jobs&#39;</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">n_jobspercore</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">fastr_plugin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">ranking_score</span><span class="o">=</span><span class="s1">&#39;test_score&#39;</span><span class="p">):</span>

        <span class="c1"># Added for fastr and joblib executions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span> <span class="o">=</span> <span class="n">param_distributions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobspercore</span> <span class="o">=</span> <span class="n">n_jobspercore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fastr_plugin</span> <span class="o">=</span> <span class="n">fastr_plugin</span>

        <span class="c1"># Below are the defaults from sklearn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_params</span> <span class="o">=</span> <span class="n">fit_params</span> <span class="k">if</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iid</span> <span class="o">=</span> <span class="n">iid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refit</span> <span class="o">=</span> <span class="n">refit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_dispatch</span> <span class="o">=</span> <span class="n">pre_dispatch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">error_score</span> <span class="o">=</span> <span class="n">error_score</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span> <span class="o">=</span> <span class="n">return_train_score</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxlen</span> <span class="o">=</span> <span class="n">maxlen</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ranking_score</span> <span class="o">=</span> <span class="n">ranking_score</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_estimator_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">_estimator_type</span>

<div class="viewcode-block" id="BaseSearchCV.score"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the score on the given data, if the estimator has been refit.</span>

<span class="sd">        This uses the score defined by ``scoring`` where provided, and the</span>
<span class="sd">        ``best_estimator_.score`` method otherwise.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape = [n_samples, n_features]</span>
<span class="sd">            Input data, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        y : array-like, shape = [n_samples] or [n_samples, n_output], optional</span>
<span class="sd">            Target relative to X for classification or regression;</span>
<span class="sd">            None for unsupervised learning.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No score function explicitly defined, &quot;</span>
                             <span class="s2">&quot;and the estimator doesn&#39;t provide one </span><span class="si">%s</span><span class="s2">&quot;</span>
                             <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method_name</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">refit</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">NotFittedError</span><span class="p">((</span><span class="s1">&#39;This GridSearchCV instance was initialized &#39;</span>
                                  <span class="s1">&#39;with refit=False. </span><span class="si">%s</span><span class="s1"> is &#39;</span>
                                  <span class="s1">&#39;available only after refitting on the best &#39;</span>
                                  <span class="s1">&#39;parameters. &#39;</span><span class="p">)</span> <span class="o">%</span> <span class="n">method_name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;best_estimator_&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="BaseSearchCV.predict"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.predict">[docs]</a>    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;best_estimator_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimator&#39;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSearchCV.predict_proba"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.predict_proba">[docs]</a>    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;best_estimator_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimator&#39;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict_proba on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict_proba``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;predict_proba&#39;</span><span class="p">)</span>

        <span class="c1"># BUG: kernel sometimes saved as unicode</span>
        <span class="c1"># BUG: SVM kernel can be wrong type</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSearchCV.predict_log_proba"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.predict_log_proba">[docs]</a>    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;best_estimator_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimator&#39;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">predict_log_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call predict_log_proba on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``predict_log_proba``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;predict_log_proba&#39;</span><span class="p">)</span>

        <span class="c1"># BUG: SVM kernel can be wrong type</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">predict_log_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict_log_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSearchCV.decision_function"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.decision_function">[docs]</a>    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;best_estimator_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimator&#39;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call decision_function on the estimator with the best found parameters.</span>

<span class="sd">        Only available if ``refit=True`` and the underlying estimator supports</span>
<span class="sd">        ``decision_function``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;decision_function&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSearchCV.transform"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.transform">[docs]</a>    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;best_estimator_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimator&#39;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call transform on the estimator with the best found parameters.</span>

<span class="sd">        Only available if the underlying estimator supports ``transform`` and</span>
<span class="sd">        ``refit=True``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        X : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;transform&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSearchCV.inverse_transform"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.inverse_transform">[docs]</a>    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;best_estimator_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimator&#39;</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xt</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call inverse_transform on the estimator with the best found params.</span>

<span class="sd">        Only available if the underlying estimator implements</span>
<span class="sd">        ``inverse_transform`` and ``refit=True``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        Xt : indexable, length n_samples</span>
<span class="sd">            Must fulfill the input assumptions of the</span>
<span class="sd">            underlying estimator.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_fitted</span><span class="p">(</span><span class="s1">&#39;inverse_transform&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Xt</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSearchCV.preprocess"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.preprocess">[docs]</a>    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Apply the available preprocssing methods to the features&#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_preprocessor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_preprocessor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_imputer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Replace nan if still left</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">replacenan</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="c1"># Only oversample in training phase, i.e. if we have the labels</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_SMOTE</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_SMOTE</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_RandomOverSampler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_RandomOverSampler</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_groupsel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_groupsel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_varsel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_varsel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_statisticalsel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_statisticalsel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_reliefsel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_reliefsel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_pca</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_modelsel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_modelsel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">best_params_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;cv_results_&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params_all&#39;</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">best_index_</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">best_score_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;cv_results_&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">best_index_</span><span class="p">]</span>

<div class="viewcode-block" id="BaseSearchCV.process_fit"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.process_fit">[docs]</a>    <span class="k">def</span> <span class="nf">process_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">,</span> <span class="n">parameters_est</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">,</span>
                    <span class="n">test_sample_counts</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span>
                    <span class="n">train_scores</span><span class="p">,</span> <span class="n">fit_time</span><span class="p">,</span> <span class="n">score_time</span><span class="p">,</span> <span class="n">cv_iter</span><span class="p">,</span>
                    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process the outcomes of a SearchCV fit and find the best settings</span>
<span class="sd">        over all cross validations from all hyperparameters tested</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We take only one result per split, default by sklearn</span>
        <span class="n">candidate_params_est</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parameters_est</span><span class="p">[::</span><span class="n">n_splits</span><span class="p">])</span>
        <span class="n">candidate_params_all</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parameters_all</span><span class="p">[::</span><span class="n">n_splits</span><span class="p">])</span>
        <span class="n">n_candidates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidate_params_est</span><span class="p">)</span>

        <span class="c1"># Computed the (weighted) mean and std for test scores alone</span>
        <span class="c1"># NOTE test_sample counts (weights) remain the same for all candidates</span>
        <span class="n">test_sample_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_sample_counts</span><span class="p">[:</span><span class="n">n_splits</span><span class="p">],</span>
                                      <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>

        <span class="c1"># Store some of the resulting scores</span>
        <span class="n">results</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">_store</span><span class="p">(</span><span class="n">key_name</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;A small helper to store the scores/times to the cv_results_&quot;&quot;&quot;</span>
            <span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_candidates</span><span class="p">,</span>
                                                              <span class="n">n_splits</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">splits</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">split_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_splits</span><span class="p">):</span>
                    <span class="n">results</span><span class="p">[</span><span class="s2">&quot;split</span><span class="si">%d</span><span class="s2">_</span><span class="si">%s</span><span class="s2">&quot;</span>
                            <span class="o">%</span> <span class="p">(</span><span class="n">split_i</span><span class="p">,</span> <span class="n">key_name</span><span class="p">)]</span> <span class="o">=</span> <span class="n">array</span><span class="p">[:,</span> <span class="n">split_i</span><span class="p">]</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="n">array_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ZeroDivisionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">e</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;[WORC Warning] </span><span class="si">{e}</span><span class="s1">. Setting </span><span class="si">{key_name}</span><span class="s1"> to unweighted.&#39;</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="n">array_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">results</span><span class="p">[</span><span class="s1">&#39;mean_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">key_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">array_means</span>

            <span class="n">array_mins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">results</span><span class="p">[</span><span class="s1">&#39;min_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">key_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">array_mins</span>

            <span class="c1"># Weighted std is not directly available in numpy</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">array_stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">((</span><span class="n">array</span> <span class="o">-</span>
                                                 <span class="n">array_means</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
                                                <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">ZeroDivisionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">e</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;[WORC Warning] </span><span class="si">{e}</span><span class="s1">. Setting </span><span class="si">{key_name}</span><span class="s1"> to unweighted.&#39;</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="n">array_stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">((</span><span class="n">array</span> <span class="o">-</span>
                                                 <span class="n">array_means</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
                                                <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

            <span class="n">results</span><span class="p">[</span><span class="s1">&#39;std_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">key_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">array_stds</span>

            <span class="k">if</span> <span class="n">rank</span><span class="p">:</span>
                <span class="n">results</span><span class="p">[</span><span class="s2">&quot;rank_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">key_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
                    <span class="n">rankdata</span><span class="p">(</span><span class="o">-</span><span class="n">array_means</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="n">_store</span><span class="p">(</span><span class="s1">&#39;test_score&#39;</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">weights</span><span class="o">=</span><span class="n">test_sample_counts</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iid</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">:</span>
            <span class="n">_store</span><span class="p">(</span><span class="s1">&#39;train_score&#39;</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">_store</span><span class="p">(</span><span class="s1">&#39;fit_time&#39;</span><span class="p">,</span> <span class="n">fit_time</span><span class="p">)</span>
        <span class="n">_store</span><span class="p">(</span><span class="s1">&#39;score_time&#39;</span><span class="p">,</span> <span class="n">score_time</span><span class="p">)</span>

        <span class="c1"># Compute the &quot;Generalization&quot; score</span>
        <span class="n">difference_score</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;mean_train_score&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">])</span>
        <span class="n">generalization_score</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">difference_score</span>
        <span class="n">results</span><span class="p">[</span><span class="s1">&#39;generalization_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">generalization_score</span>
        <span class="n">results</span><span class="p">[</span><span class="s1">&#39;rank_generalization_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
            <span class="n">rankdata</span><span class="p">(</span><span class="o">-</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;generalization_score&#39;</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="c1"># Rank the indices of scores from all parameter settings</span>
        <span class="n">ranked_test_scores</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;rank_&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranking_score</span><span class="p">]</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranked_test_scores</span><span class="p">))</span>
        <span class="n">sortedindices</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">ranked_test_scores</span><span class="p">,</span> <span class="n">indices</span><span class="p">))]</span>

        <span class="c1"># In order to reduce the memory used, we will only save</span>
        <span class="c1"># a maximum of results</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">n_candidates</span><span class="p">)</span>
        <span class="n">bestindices</span> <span class="o">=</span> <span class="n">sortedindices</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">maxlen</span><span class="p">]</span>

        <span class="n">candidate_params_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">candidate_params_est</span><span class="p">)[</span><span class="n">bestindices</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">candidate_params_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">candidate_params_all</span><span class="p">)[</span><span class="n">bestindices</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">results</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">bestindices</span><span class="p">]</span>
        <span class="n">n_candidates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidate_params_est</span><span class="p">)</span>

        <span class="c1"># Store the atributes of the best performing estimator</span>
        <span class="n">best_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;rank_&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranking_score</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">best_parameters_est</span> <span class="o">=</span> <span class="n">candidate_params_est</span><span class="p">[</span><span class="n">best_index</span><span class="p">]</span>
        <span class="n">best_parameters_all</span> <span class="o">=</span> <span class="n">candidate_params_all</span><span class="p">[</span><span class="n">best_index</span><span class="p">]</span>

        <span class="c1"># Use one MaskedArray and mask all the places where the param is not</span>
        <span class="c1"># applicable for that candidate. Use defaultdict as each candidate may</span>
        <span class="c1"># not contain all the params</span>
        <span class="n">param_results</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">MaskedArray</span><span class="p">,</span>
                                            <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_candidates</span><span class="p">,),</span>
                                            <span class="n">mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                            <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">cand_i</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">candidate_params_all</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># An all masked empty array gets created for the key</span>
                <span class="c1"># `&quot;param_%s&quot; % name` at the first occurence of `name`.</span>
                <span class="c1"># Setting the value at an index also unmasks that index</span>
                <span class="n">param_results</span><span class="p">[</span><span class="s2">&quot;param_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">][</span><span class="n">cand_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="c1"># Store a list of param dicts at the key &#39;params&#39;</span>
        <span class="n">results</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">candidate_params_est</span>
        <span class="n">results</span><span class="p">[</span><span class="s1">&#39;params_all&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">candidate_params_all</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cv_results_</span> <span class="o">=</span> <span class="n">results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_index_</span> <span class="o">=</span> <span class="n">best_index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_splits_</span> <span class="o">=</span> <span class="n">n_splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv_iter</span> <span class="o">=</span> <span class="n">cv_iter</span>

        <span class="c1"># Refit all objects with best settings on the full dataset</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refit_and_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">best_parameters_all</span><span class="p">,</span> <span class="n">best_parameters_est</span><span class="p">,</span>
                             <span class="n">train</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="n">indices</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="BaseSearchCV.refit_and_score"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.refit_and_score">[docs]</a>    <span class="k">def</span> <span class="nf">refit_and_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">,</span> <span class="n">parameters_est</span><span class="p">,</span>
                        <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Refit the base estimator and attributes such as GroupSel</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: array, mandatory</span>
<span class="sd">                Array containingfor each object (rows) the feature values</span>
<span class="sd">                (1st Column) and the associated feature label (2nd Column).</span>

<span class="sd">        y: list(?), mandatory</span>
<span class="sd">                List containing the labels of the objects.</span>

<span class="sd">        parameters_all: dictionary, mandatory</span>
<span class="sd">                Contains the settings used for the all preprocessing functions</span>
<span class="sd">                and the fitting. TODO: Create a default object and show the</span>
<span class="sd">                fields.</span>

<span class="sd">        parameters_est: dictionary, mandatory</span>
<span class="sd">                Contains the settings used for the base estimator</span>

<span class="sd">        train: list, mandatory</span>
<span class="sd">                Indices of the objects to be used as training set.</span>

<span class="sd">        test: list, mandatory</span>
<span class="sd">                Indices of the objects to be used as testing set.</span>


<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>

        <span class="c1"># Refit all preprocessing functions</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">fit_and_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span>
                            <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">,</span>
                            <span class="n">fit_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_params</span><span class="p">,</span>
                            <span class="n">return_train_score</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">,</span>
                            <span class="n">return_n_test_samples</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">return_times</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_parameters</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">error_score</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">error_score</span><span class="p">,</span>
                            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                            <span class="n">return_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Associate best options with new fits</span>
        <span class="p">(</span><span class="n">save_data</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">,</span> <span class="n">scalers</span><span class="p">,</span>\
            <span class="n">Imputers</span><span class="p">,</span> <span class="n">Preprocessors</span><span class="p">,</span> <span class="n">PCAs</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">sm</span><span class="p">,</span> <span class="n">ros</span><span class="p">)</span> <span class="o">=</span> <span class="n">out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_groupsel</span> <span class="o">=</span> <span class="n">GroupSel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_scaler</span> <span class="o">=</span> <span class="n">scalers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_varsel</span> <span class="o">=</span> <span class="n">VarSel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_modelsel</span> <span class="o">=</span> <span class="n">SelectModel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_preprocessor</span> <span class="o">=</span> <span class="n">Preprocessors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_imputer</span> <span class="o">=</span> <span class="n">Imputers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_pca</span> <span class="o">=</span> <span class="n">PCAs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_featlab</span> <span class="o">=</span> <span class="n">feature_labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_statisticalsel</span> <span class="o">=</span> <span class="n">StatisticalSel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_reliefsel</span> <span class="o">=</span> <span class="n">ReliefSel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_SMOTE</span> <span class="o">=</span> <span class="n">sm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_RandomOverSampler</span> <span class="o">=</span> <span class="n">ros</span>

        <span class="c1"># Fit the estimator using the preprocessed features</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">parameters_est</span> <span class="o">=</span> <span class="n">delete_nonestimator_parameters</span><span class="p">(</span><span class="n">parameters_est</span><span class="p">)</span>
        <span class="n">best_estimator</span> <span class="o">=</span> <span class="n">cc</span><span class="o">.</span><span class="n">construct_classifier</span><span class="p">(</span><span class="n">parameters_all</span><span class="p">)</span>

        <span class="c1"># NOTE: This just has to go to the construct classifier function,</span>
        <span class="c1"># although it is more convenient here due to the hyperparameter search</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
            <span class="n">labellength</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">labellength</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
                <span class="n">labellength</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">labellength</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">best_estimator</span><span class="p">)</span> <span class="o">!=</span> <span class="n">RankedSVM</span><span class="p">:</span>
            <span class="c1"># Multiclass, hence employ a multiclass classifier for e.g. SVM, RF</span>
            <span class="n">best_estimator</span> <span class="o">=</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">best_estimator</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">best_estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">best_estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="n">best_estimator</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="BaseSearchCV.create_ensemble"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCV.create_ensemble">[docs]</a>    <span class="k">def</span> <span class="nf">create_ensemble</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initialize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>

<span class="sd">        Create an (optimal) ensemble of a combination of hyperparameter settings</span>
<span class="sd">        and the associated groupsels, PCAs, estimators etc.</span>

<span class="sd">        Based on Caruana et al. 2004, but a little different:</span>

<span class="sd">        1. Recreate the training/validation splits for a n-fold cross validation.</span>
<span class="sd">        2. For each fold:</span>
<span class="sd">            a. Start with an empty ensemble</span>
<span class="sd">            b. Create starting ensemble by adding N individually best performing</span>
<span class="sd">               models on the validation set. N is tuned on the validation set.</span>
<span class="sd">            c. Add model that improves ensemble performance on validation set the most, with replacement.</span>
<span class="sd">            d. Repeat (c) untill performance does not increase</span>

<span class="sd">        The performance metric is the same as for the original hyperparameter</span>
<span class="sd">        search, i.e. probably the F1-score for classification and r2-score</span>
<span class="sd">        for regression. However, we recommend using the SAR score, as this is</span>
<span class="sd">        more universal.</span>

<span class="sd">        Method: top50 or Caruana</span>

<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c1"># Define a function for scoring the performance of a classifier</span>
        <span class="k">def</span> <span class="nf">compute_performance</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span> <span class="n">Y_valid_truth</span><span class="p">,</span> <span class="n">Y_valid_score</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">scoring</span> <span class="o">==</span> <span class="s1">&#39;f1_weighted&#39;</span><span class="p">:</span>
                <span class="c1"># Convert score to binaries first</span>
                <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">Y_valid_score</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">:</span>
                        <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="n">perf</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Y_valid_truth</span><span class="p">,</span> <span class="n">Y_valid_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">scoring</span> <span class="o">==</span> <span class="s1">&#39;auc&#39;</span><span class="p">:</span>
                <span class="n">perf</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">Y_valid_truth</span><span class="p">,</span> <span class="n">Y_valid_score</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">scoring</span> <span class="o">==</span> <span class="s1">&#39;sar&#39;</span><span class="p">:</span>
                <span class="n">perf</span> <span class="o">=</span> <span class="n">sar_score</span><span class="p">(</span><span class="n">Y_valid_truth</span><span class="p">,</span> <span class="n">Y_valid_score</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s1">&#39;[WORC Warning] No valid score method given in ensembling: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">scoring</span><span class="p">))</span>

            <span class="k">return</span> <span class="n">perf</span>

        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>

        <span class="k">if</span> <span class="n">scoring</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scoring</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span>

        <span class="c1"># Get settings for best 100 estimators</span>
        <span class="n">parameters_est</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span>
        <span class="n">parameters_all</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params_all&#39;</span><span class="p">]</span>
        <span class="n">n_classifiers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters_est</span><span class="p">)</span>
        <span class="n">n_iter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_iter</span><span class="p">)</span>

        <span class="c1"># Create a new base object for the ensemble components</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="n">RandomizedSearchCVfastr</span><span class="p">:</span>
            <span class="n">base_estimator</span> <span class="o">=</span> <span class="n">RandomizedSearchCVfastr</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="n">RandomizedSearchCVJoblib</span><span class="p">:</span>
            <span class="n">base_estimator</span> <span class="o">=</span> <span class="n">RandomizedSearchCVJoblib</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">method</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">int</span><span class="p">:</span>
            <span class="c1"># Simply take the top50 best hyperparameters</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Creating ensemble using top {str(method)} individual classifiers.&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Next functions expect list</span>
                <span class="n">ensemble</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ensemble</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;FitNumber&#39;</span><span class="p">:</span>
            <span class="c1"># Use optimum number of models</span>

            <span class="c1"># In order to speed up the process, we precompute all scores of the possible</span>
            <span class="c1"># classifiers in all cross validation estimatons</span>

            <span class="c1"># Create the training and validation set scores</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precomputing scores on training and validation set.&#39;</span><span class="p">)</span>
            <span class="n">Y_valid_score</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="n">Y_valid_truth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="n">performances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">n_classifiers</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">it</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_iter</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39; - iteration {it + 1} / </span><span class="si">{n_iter}</span><span class="s1">.&#39;</span><span class="p">)</span>
                <span class="n">Y_valid_score_it</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_classifiers</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)))</span>

                <span class="c1"># Loop over the 100 best estimators</span>
                <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="p">(</span><span class="n">p_est</span><span class="p">,</span> <span class="n">p_all</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">parameters_est</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">)):</span>
                    <span class="c1"># NOTE: Explicitly exclude validation set, elso refit and score</span>
                    <span class="c1"># somehow still seems to use it.</span>
                    <span class="n">X_train_temp</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train</span><span class="p">]</span>
                    <span class="n">Y_train_temp</span> <span class="o">=</span> <span class="p">[</span><span class="n">Y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train</span><span class="p">]</span>
                    <span class="n">train_temp</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>

                    <span class="c1"># Refit a SearchCV object with the provided parameters</span>
                    <span class="n">base_estimator</span><span class="o">.</span><span class="n">refit_and_score</span><span class="p">(</span><span class="n">X_train_temp</span><span class="p">,</span> <span class="n">Y_train_temp</span><span class="p">,</span> <span class="n">p_all</span><span class="p">,</span>
                                                   <span class="n">p_est</span><span class="p">,</span> <span class="n">train_temp</span><span class="p">,</span> <span class="n">train_temp</span><span class="p">,</span>
                                                   <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                    <span class="c1"># Predict and save scores</span>
                    <span class="n">X_train_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X_train</span><span class="p">]</span> <span class="c1"># Throw away labels</span>
                    <span class="n">X_train_values_valid</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">valid</span><span class="p">]</span>
                    <span class="n">Y_valid_score_temp</span> <span class="o">=</span> <span class="n">base_estimator</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_values_valid</span><span class="p">)</span>

                    <span class="c1"># Only take the probabilities for the second class</span>
                    <span class="n">Y_valid_score_temp</span> <span class="o">=</span> <span class="n">Y_valid_score_temp</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

                    <span class="c1"># Append to array for all classifiers on this validation set</span>
                    <span class="n">Y_valid_score_it</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">Y_valid_score_temp</span>

                    <span class="k">if</span> <span class="n">num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="c1"># Also store the validation ground truths</span>
                        <span class="n">Y_valid_truth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y_train</span><span class="p">[</span><span class="n">valid</span><span class="p">])</span>

                    <span class="n">performances</span><span class="p">[</span><span class="n">it</span><span class="p">,</span> <span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_performance</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span>
                                                                <span class="n">Y_train</span><span class="p">[</span><span class="n">valid</span><span class="p">],</span>
                                                                <span class="n">Y_valid_score_temp</span><span class="p">)</span>

                <span class="n">Y_valid_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y_valid_score_it</span><span class="p">)</span>

            <span class="c1"># Sorted Ensemble Initialization -------------------------------------</span>
            <span class="c1"># Go on adding to the ensemble untill we find the optimal performance</span>
            <span class="c1"># Initialize variables</span>

            <span class="c1"># Note: doing this in a greedy way doesnt work. We compute the</span>
            <span class="c1"># performances for the ensembles of lengt [1, n_classifiers] and</span>
            <span class="c1"># select the optimum</span>
            <span class="n">best_performance</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">new_performance</span> <span class="o">=</span> <span class="mf">0.001</span>
            <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">ensemble</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="n">y_score</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_iter</span>
            <span class="n">best_index</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">single_estimator_performance</span> <span class="o">=</span> <span class="n">new_performance</span>

            <span class="k">if</span> <span class="n">initialize</span><span class="p">:</span>
                <span class="c1"># Rank the models based on scoring on the validation set</span>
                <span class="n">performances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">performances</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">sortedindices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">performances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">performances_n_class</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sorted Ensemble Initialization.&#39;</span><span class="p">)</span>
                <span class="c1"># while new_performance &gt; best_performance:</span>
                <span class="k">for</span> <span class="n">dummy</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classifiers</span><span class="p">):</span>
                    <span class="c1"># Score is better, so expand ensemble and replace new best score</span>
                    <span class="n">best_performance</span> <span class="o">=</span> <span class="n">new_performance</span>

                    <span class="k">if</span> <span class="n">iteration</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Stack scores: not needed for first iteration</span>
                        <span class="n">ensemble</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_index</span><span class="p">)</span>
                        <span class="c1"># N_models += 1</span>
                        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                            <span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">],</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">][</span><span class="n">ensemble</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]))</span>

                    <span class="k">elif</span> <span class="n">iteration</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Create y_score object for second iteration</span>
                        <span class="n">single_estimator_performance</span> <span class="o">=</span> <span class="n">new_performance</span>
                        <span class="n">ensemble</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_index</span><span class="p">)</span>
                        <span class="c1"># N_models += 1</span>
                        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                            <span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">][</span><span class="n">ensemble</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>

                    <span class="c1"># Perform n-fold cross validation to estimate performance of next best classifier</span>
                    <span class="n">performances_temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_iter</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">n_crossval</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                        <span class="c1"># For each estimator, add the score to the ensemble and new ensemble performance</span>
                        <span class="k">if</span> <span class="n">iteration</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="c1"># No y_score yet, so we need to build it instead of stacking</span>
                            <span class="n">y_valid_score_new</span> <span class="o">=</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">][</span><span class="n">sortedindices</span><span class="p">[</span><span class="n">iteration</span><span class="p">],</span> <span class="p">:]</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Stack scores of added model on top of previous scores and average</span>
                            <span class="n">y_valid_score_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">],</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">][</span><span class="n">sortedindices</span><span class="p">[</span><span class="n">iteration</span><span class="p">],</span> <span class="p">:])),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                        <span class="n">perf</span> <span class="o">=</span> <span class="n">compute_performance</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span> <span class="n">Y_valid_truth</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">],</span> <span class="n">y_valid_score_new</span><span class="p">)</span>
                        <span class="n">performances_temp</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">]</span> <span class="o">=</span> <span class="n">perf</span>

                    <span class="c1"># Check which ensemble should be in the ensemble to maximally improve</span>
                    <span class="n">new_performance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">performances_temp</span><span class="p">)</span>
                    <span class="n">performances_n_class</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_performance</span><span class="p">)</span>
                    <span class="n">best_index</span> <span class="o">=</span> <span class="n">sortedindices</span><span class="p">[</span><span class="n">iteration</span><span class="p">]</span>
                    <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Select N_models for initialization</span>
                <span class="n">new_performance</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">performances_n_class</span><span class="p">)</span>
                <span class="n">N_models</span> <span class="o">=</span> <span class="n">performances_n_class</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">new_performance</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># +1 due to python indexing</span>
                <span class="n">ensemble</span> <span class="o">=</span> <span class="n">ensemble</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">N_models</span><span class="p">]</span>
                <span class="n">best_performance</span> <span class="o">=</span> <span class="n">new_performance</span>

                <span class="c1"># Print the performance gain</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensembling best </span><span class="si">{scoring}</span><span class="s2">: </span><span class="si">{best_performance}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Single estimator best </span><span class="si">{scoring}</span><span class="s2">: </span><span class="si">{single_estimator_performance}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Ensemble consists of {len(ensemble)} estimators </span><span class="si">{ensemble}</span><span class="s1">.&#39;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;Caruana&#39;</span><span class="p">:</span>
            <span class="c1"># Use the method from Caruana</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Creating ensemble with Caruana method.&#39;</span><span class="p">)</span>

            <span class="c1"># BUG: kernel parameter is sometimes saved in unicode</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters_est</span><span class="p">)):</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters_est</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sa">u</span><span class="s1">&#39;kernel&#39;</span><span class="p">])</span>
                <span class="k">del</span> <span class="n">parameters_est</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sa">u</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span>
                <span class="k">del</span> <span class="n">parameters_all</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sa">u</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span>
                <span class="n">parameters_est</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kernel</span>
                <span class="n">parameters_all</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kernel</span>

            <span class="c1"># In order to speed up the process, we precompute all scores of the possible</span>
            <span class="c1"># classifiers in all cross validation estimatons</span>

            <span class="c1"># Create the training and validation set scores</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precomputing scores on training and validation set.&#39;</span><span class="p">)</span>
            <span class="n">Y_valid_score</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="n">Y_valid_truth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="n">performances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">n_classifiers</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">it</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_iter</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39; - iteration {it + 1} / </span><span class="si">{n_iter}</span><span class="s1">.&#39;</span><span class="p">)</span>
                <span class="n">Y_valid_score_it</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_classifiers</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)))</span>

                <span class="c1"># Loop over the 100 best estimators</span>
                <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="p">(</span><span class="n">p_est</span><span class="p">,</span> <span class="n">p_all</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">parameters_est</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">)):</span>
                    <span class="c1"># NOTE: Explicitly exclude validation set, elso refit and score</span>
                    <span class="c1"># somehow still seems to use it.</span>
                    <span class="n">X_train_temp</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train</span><span class="p">]</span>
                    <span class="n">Y_train_temp</span> <span class="o">=</span> <span class="p">[</span><span class="n">Y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train</span><span class="p">]</span>
                    <span class="n">train_temp</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>

                    <span class="c1"># Refit a SearchCV object with the provided parameters</span>
                    <span class="n">base_estimator</span><span class="o">.</span><span class="n">refit_and_score</span><span class="p">(</span><span class="n">X_train_temp</span><span class="p">,</span> <span class="n">Y_train_temp</span><span class="p">,</span> <span class="n">p_all</span><span class="p">,</span>
                                                   <span class="n">p_est</span><span class="p">,</span> <span class="n">train_temp</span><span class="p">,</span> <span class="n">train_temp</span><span class="p">,</span>
                                                   <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                    <span class="c1"># Predict and save scores</span>
                    <span class="n">X_train_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X_train</span><span class="p">]</span> <span class="c1"># Throw away labels</span>
                    <span class="n">X_train_values_valid</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">valid</span><span class="p">]</span>
                    <span class="n">Y_valid_score_temp</span> <span class="o">=</span> <span class="n">base_estimator</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_values_valid</span><span class="p">)</span>

                    <span class="c1"># Only take the probabilities for the second class</span>
                    <span class="n">Y_valid_score_temp</span> <span class="o">=</span> <span class="n">Y_valid_score_temp</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

                    <span class="c1"># Append to array for all classifiers on this validation set</span>
                    <span class="n">Y_valid_score_it</span><span class="p">[</span><span class="n">num</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">Y_valid_score_temp</span>

                    <span class="k">if</span> <span class="n">num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="c1"># Also store the validation ground truths</span>
                        <span class="n">Y_valid_truth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y_train</span><span class="p">[</span><span class="n">valid</span><span class="p">])</span>

                    <span class="n">performances</span><span class="p">[</span><span class="n">it</span><span class="p">,</span> <span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_performance</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span>
                                                                <span class="n">Y_train</span><span class="p">[</span><span class="n">valid</span><span class="p">],</span>
                                                                <span class="n">Y_valid_score_temp</span><span class="p">)</span>

                <span class="n">Y_valid_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y_valid_score_it</span><span class="p">)</span>

            <span class="c1"># Sorted Ensemble Initialization -------------------------------------</span>
            <span class="c1"># Go on adding to the ensemble untill we find the optimal performance</span>
            <span class="c1"># Initialize variables</span>

            <span class="c1"># Note: doing this in a greedy way doesnt work. We compute the</span>
            <span class="c1"># performances for the ensembles of lengt [1, n_classifiers] and</span>
            <span class="c1"># select the optimum</span>
            <span class="n">best_performance</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">new_performance</span> <span class="o">=</span> <span class="mf">0.001</span>
            <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">ensemble</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="n">y_score</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_iter</span>
            <span class="n">best_index</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">single_estimator_performance</span> <span class="o">=</span> <span class="n">new_performance</span>

            <span class="k">if</span> <span class="n">initialize</span><span class="p">:</span>
                <span class="c1"># Rank the models based on scoring on the validation set</span>
                <span class="n">performances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">performances</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">sortedindices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">performances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">performances_n_class</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sorted Ensemble Initialization.&#39;</span><span class="p">)</span>
                <span class="c1"># while new_performance &gt; best_performance:</span>
                <span class="k">for</span> <span class="n">dummy</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classifiers</span><span class="p">):</span>
                    <span class="c1"># Score is better, so expand ensemble and replace new best score</span>
                    <span class="n">best_performance</span> <span class="o">=</span> <span class="n">new_performance</span>

                    <span class="k">if</span> <span class="n">iteration</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Stack scores: not needed for first iteration</span>
                        <span class="n">ensemble</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_index</span><span class="p">)</span>
                        <span class="c1"># N_models += 1</span>
                        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                            <span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">],</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">][</span><span class="n">ensemble</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]))</span>

                    <span class="k">elif</span> <span class="n">iteration</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Create y_score object for second iteration</span>
                        <span class="n">single_estimator_performance</span> <span class="o">=</span> <span class="n">new_performance</span>
                        <span class="n">ensemble</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_index</span><span class="p">)</span>
                        <span class="c1"># N_models += 1</span>
                        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                            <span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">][</span><span class="n">ensemble</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>

                    <span class="c1"># Perform n-fold cross validation to estimate performance of next best classifier</span>
                    <span class="n">performances_temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_iter</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">n_crossval</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                        <span class="c1"># For each estimator, add the score to the ensemble and new ensemble performance</span>
                        <span class="k">if</span> <span class="n">iteration</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="c1"># No y_score yet, so we need to build it instead of stacking</span>
                            <span class="n">y_valid_score_new</span> <span class="o">=</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">][</span><span class="n">sortedindices</span><span class="p">[</span><span class="n">iteration</span><span class="p">],</span> <span class="p">:]</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Stack scores of added model on top of previous scores and average</span>
                            <span class="n">y_valid_score_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">],</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">][</span><span class="n">sortedindices</span><span class="p">[</span><span class="n">iteration</span><span class="p">],</span> <span class="p">:])),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                        <span class="n">perf</span> <span class="o">=</span> <span class="n">compute_performance</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span> <span class="n">Y_valid_truth</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">],</span> <span class="n">y_valid_score_new</span><span class="p">)</span>
                        <span class="n">performances_temp</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">]</span> <span class="o">=</span> <span class="n">perf</span>

                    <span class="c1"># Check which ensemble should be in the ensemble to maximally improve</span>
                    <span class="n">new_performance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">performances_temp</span><span class="p">)</span>
                    <span class="n">performances_n_class</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_performance</span><span class="p">)</span>
                    <span class="n">best_index</span> <span class="o">=</span> <span class="n">sortedindices</span><span class="p">[</span><span class="n">iteration</span><span class="p">]</span>
                    <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Select N_models for initialization</span>
                <span class="n">new_performance</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">performances_n_class</span><span class="p">)</span>
                <span class="n">N_models</span> <span class="o">=</span> <span class="n">performances_n_class</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">new_performance</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># +1 due to python indexing</span>
                <span class="n">ensemble</span> <span class="o">=</span> <span class="n">ensemble</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">N_models</span><span class="p">]</span>
                <span class="n">best_performance</span> <span class="o">=</span> <span class="n">new_performance</span>

                <span class="c1"># Print the performance gain</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensembling best </span><span class="si">{scoring}</span><span class="s2">: </span><span class="si">{best_performance}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Single estimator best </span><span class="si">{scoring}</span><span class="s2">: </span><span class="si">{single_estimator_performance}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Ensemble consists of {len(ensemble)} estimators </span><span class="si">{ensemble}</span><span class="s1">.&#39;</span><span class="p">)</span>

            <span class="c1"># Greedy selection  -----------------------------------------------</span>
            <span class="c1"># Initialize variables</span>
            <span class="n">best_performance</span> <span class="o">-=</span> <span class="mf">1e-10</span>
            <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Go on adding to the ensemble untill we find the optimal performance</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Greedy selection.&#39;</span><span class="p">)</span>
            <span class="k">while</span> <span class="n">new_performance</span> <span class="o">&gt;</span> <span class="n">best_performance</span><span class="p">:</span>
                <span class="c1"># Score is better, so expand ensemble and replace new best score</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration: </span><span class="si">{iteration}</span><span class="s2">, best </span><span class="si">{scoring}</span><span class="s2">: </span><span class="si">{new_performance}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="n">best_performance</span> <span class="o">=</span> <span class="n">new_performance</span>

                <span class="k">if</span> <span class="n">iteration</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># Stack scores: not needed for first iteration</span>
                    <span class="n">ensemble</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_index</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                        <span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">],</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">][</span><span class="n">ensemble</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]))</span>

                <span class="k">elif</span> <span class="n">iteration</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">initialize</span><span class="p">:</span>
                        <span class="c1"># Create y_score object for second iteration</span>
                        <span class="n">single_estimator_performance</span> <span class="o">=</span> <span class="n">new_performance</span>
                        <span class="n">ensemble</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_index</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                            <span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">][</span><span class="n">ensemble</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Stack scores: not needed when ensemble initialization is already used</span>
                        <span class="n">ensemble</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_index</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                            <span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_score</span><span class="p">[</span><span class="n">num</span><span class="p">],</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">num</span><span class="p">][</span><span class="n">ensemble</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]))</span>

                <span class="c1"># Perform n-fold cross validation to estimate performance of each possible addition to ensemble</span>
                <span class="n">performances_temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">n_classifiers</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">n_crossval</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">):</span>
                    <span class="c1"># For each estimator, add the score to the ensemble and new ensemble performance</span>
                    <span class="k">for</span> <span class="n">n_estimator</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classifiers</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">iteration</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="c1"># No y_score yet, so we need to build it instead of stacking</span>
                            <span class="n">y_valid_score_new</span> <span class="o">=</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">][</span><span class="n">n_estimator</span><span class="p">,</span> <span class="p">:]</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Stack scores of added model on top of previous scores and average</span>
                            <span class="n">y_valid_score_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">],</span> <span class="n">Y_valid_score</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">][</span><span class="n">n_estimator</span><span class="p">,</span> <span class="p">:])),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                        <span class="n">perf</span> <span class="o">=</span> <span class="n">compute_performance</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span> <span class="n">Y_valid_truth</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">],</span> <span class="n">y_valid_score_new</span><span class="p">)</span>
                        <span class="n">performances_temp</span><span class="p">[</span><span class="n">n_crossval</span><span class="p">,</span> <span class="n">n_estimator</span><span class="p">]</span> <span class="o">=</span> <span class="n">perf</span>

                <span class="c1"># Average performances over crossval</span>
                <span class="n">performances_temp</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">performances_temp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

                <span class="c1"># Check which ensemble should be in the ensemble to maximally improve</span>
                <span class="n">new_performance</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">performances_temp</span><span class="p">)</span>
                <span class="n">best_index</span> <span class="o">=</span> <span class="n">performances_temp</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">new_performance</span><span class="p">)</span>
                <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Print the performance gain</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensembling best </span><span class="si">{scoring}</span><span class="s2">: </span><span class="si">{best_performance}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Single estimator best </span><span class="si">{scoring}</span><span class="s2">: </span><span class="si">{single_estimator_performance}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Ensemble consists of {len(ensemble)} estimators </span><span class="si">{ensemble}</span><span class="s1">.&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[WORC WARNING] No valid ensemble method given: </span><span class="si">{method}</span><span class="s1">. Not ensembling&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># Create the ensemble --------------------------------------------------</span>
        <span class="c1"># Create the ensemble trained on the full training set</span>
        <span class="n">parameters_est</span> <span class="o">=</span> <span class="p">[</span><span class="n">parameters_est</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ensemble</span><span class="p">]</span>
        <span class="n">parameters_all</span> <span class="o">=</span> <span class="p">[</span><span class="n">parameters_all</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ensemble</span><span class="p">]</span>
        <span class="n">estimators</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">train</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
        <span class="n">nest</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ensemble</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">enum</span><span class="p">,</span> <span class="p">(</span><span class="n">p_est</span><span class="p">,</span> <span class="n">p_all</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">parameters_est</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">)):</span>
            <span class="c1"># Refit a SearchCV object with the provided parameters</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Refitting estimator {enum+1} / </span><span class="si">{nest}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="n">base_estimator</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">)</span>

            <span class="c1"># # Check if we need to create a multiclass estimator</span>
            <span class="c1"># if Y_train.shape[1] &gt; 1 and type(base_estimator) != RankedSVM:</span>
            <span class="c1">#     # Multiclass, hence employ a multiclass classifier for SVM</span>
            <span class="c1">#     base_estimator = OneVsRestClassifier(base_estimator)</span>

            <span class="n">base_estimator</span><span class="o">.</span><span class="n">refit_and_score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">p_all</span><span class="p">,</span>
                                           <span class="n">p_est</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span>
                                           <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">estimators</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span> <span class="o">=</span> <span class="n">Ensemble</span><span class="p">(</span><span class="n">estimators</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BaseSearchCVfastr"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCVfastr">[docs]</a><span class="k">class</span> <span class="nc">BaseSearchCVfastr</span><span class="p">(</span><span class="n">BaseSearchCV</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for hyper parameter search with cross-validation.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">parameter_iterable</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Actual fitting,  performing the search over parameters.&quot;&quot;&quot;</span>

        <span class="n">regressors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SVR&#39;</span><span class="p">,</span> <span class="s1">&#39;RFR&#39;</span><span class="p">,</span> <span class="s1">&#39;SGDR&#39;</span><span class="p">,</span> <span class="s1">&#39;Lasso&#39;</span><span class="p">,</span> <span class="s1">&#39;ElasticNet&#39;</span><span class="p">]</span>
        <span class="n">isclassifier</span> <span class="o">=</span>\
            <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">clf</span> <span class="ow">in</span> <span class="n">regressors</span> <span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">[</span><span class="s1">&#39;classifiers&#39;</span><span class="p">])</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">isclassifier</span><span class="p">)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameter_iterable</span><span class="p">,</span> <span class="n">Sized</span><span class="p">):</span>
            <span class="n">n_candidates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameter_iterable</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fitting </span><span class="si">{n_splits}</span><span class="s2"> folds for each of </span><span class="si">{n_candidates}</span><span class="s2"> candidates, totalling {n_candidates * n_splits} fits.&quot;</span><span class="p">)</span>

        <span class="n">cv_iter</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">))</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_uppercase</span> <span class="o">+</span> <span class="n">string</span><span class="o">.</span><span class="n">digits</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
        <span class="n">tempfolder</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">fastr</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">mounts</span><span class="p">[</span><span class="s1">&#39;tmp&#39;</span><span class="p">],</span> <span class="s1">&#39;GS&#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tempfolder</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">tempfolder</span><span class="p">)</span>

        <span class="c1"># Create the parameter files</span>
        <span class="n">parameters_temp</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">parameter_iterable</span><span class="p">):</span>

                <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;Number&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>
                <span class="n">parameters_temp</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">)]</span> <span class="o">=</span> <span class="n">parameters</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="c1"># One of the parameters gives an error. Find out which one.</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameter_iterable</span><span class="o">.</span><span class="n">param_distributions</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                <span class="n">sampled_params</span> <span class="o">=</span> <span class="n">ParameterSampler</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sampled_params</span><span class="p">):</span>
                        <span class="n">a</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;One or more of the values in your parameter sampler &#39;</span> <span class="o">+</span>\
                      <span class="s1">&#39;is either not iterable, or the distribution cannot &#39;</span> <span class="o">+</span>\
                      <span class="s1">&#39;generate valid samples. Please check your  &#39;</span> <span class="o">+</span>\
                      <span class="sa">f</span><span class="s1">&#39; parameters. At least </span><span class="si">{k}</span><span class="s1"> gives an error.&#39;</span>
            <span class="k">raise</span> <span class="n">WORCexceptions</span><span class="o">.</span><span class="n">WORCValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

        <span class="c1"># Split the parameters files in equal parts</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parameters_temp</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">chunks</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_jobspercore</span><span class="p">)</span>
        <span class="n">parameter_files</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">keys</span><span class="p">):</span>
            <span class="n">temp_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">number</span> <span class="ow">in</span> <span class="n">k</span><span class="p">:</span>
                <span class="n">temp_dict</span><span class="p">[</span><span class="n">number</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters_temp</span><span class="p">[</span><span class="n">number</span><span class="p">]</span>

            <span class="n">fname</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;settings_</span><span class="si">{num}</span><span class="s1">.json&#39;</span>
            <span class="n">sourcename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfolder</span><span class="p">,</span> <span class="s1">&#39;parameters&#39;</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">sourcename</span><span class="p">)):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">sourcename</span><span class="p">))</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">sourcename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">temp_dict</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

            <span class="n">parameter_files</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">)]</span> <span class="o">=</span>\
                <span class="sa">f</span><span class="s1">&#39;vfs://tmp/GS/</span><span class="si">{name}</span><span class="s1">/parameters/</span><span class="si">{fname}</span><span class="s1">&#39;</span>

        <span class="c1"># Create test-train splits</span>
        <span class="n">traintest_files</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># TODO: ugly nummering solution</span>
        <span class="n">num</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv_iter</span><span class="p">:</span>
            <span class="n">source_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]</span>

            <span class="n">source_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">],</span>
                                    <span class="n">index</span><span class="o">=</span><span class="n">source_labels</span><span class="p">,</span>
                                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Train-test data&#39;</span><span class="p">)</span>

            <span class="n">fname</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;traintest_</span><span class="si">{num}</span><span class="s1">.hdf5&#39;</span>
            <span class="n">sourcename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfolder</span><span class="p">,</span> <span class="s1">&#39;traintest&#39;</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">sourcename</span><span class="p">)):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">sourcename</span><span class="p">))</span>
            <span class="n">traintest_files</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">)]</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;vfs://tmp/GS/</span><span class="si">{name}</span><span class="s1">/traintest/</span><span class="si">{fname}</span><span class="s1">&#39;</span>

            <span class="n">sourcelabel</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Source Data Iteration </span><span class="si">{num}</span><span class="s2">&quot;</span>
            <span class="n">source_data</span><span class="o">.</span><span class="n">to_hdf</span><span class="p">(</span><span class="n">sourcename</span><span class="p">,</span> <span class="n">sourcelabel</span><span class="p">)</span>

            <span class="n">num</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Create the files containing the estimator and settings</span>
        <span class="n">estimator_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;scoring&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;verbose&#39;</span><span class="p">,</span> <span class="s1">&#39;fit_params&#39;</span><span class="p">,</span> <span class="s1">&#39;return_train_score&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;return_n_test_samples&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;return_times&#39;</span><span class="p">,</span> <span class="s1">&#39;return_parameters&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;error_score&#39;</span><span class="p">]</span>

        <span class="n">estimator_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span>
                                    <span class="kc">False</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">fit_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">,</span>
                                    <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">error_score</span><span class="p">],</span>
                                   <span class="n">index</span><span class="o">=</span><span class="n">estimator_labels</span><span class="p">,</span>
                                   <span class="n">name</span><span class="o">=</span><span class="s1">&#39;estimator Data&#39;</span><span class="p">)</span>
        <span class="n">fname</span> <span class="o">=</span> <span class="s1">&#39;estimatordata.hdf5&#39;</span>
        <span class="n">estimatorname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfolder</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>
        <span class="n">estimator_data</span><span class="o">.</span><span class="n">to_hdf</span><span class="p">(</span><span class="n">estimatorname</span><span class="p">,</span> <span class="s1">&#39;Estimator Data&#39;</span><span class="p">)</span>

        <span class="n">estimatordata</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;vfs://tmp/GS/</span><span class="si">{name}</span><span class="s2">/</span><span class="si">{fname}</span><span class="s2">&quot;</span>

        <span class="c1"># Create the fastr network</span>
        <span class="n">network</span> <span class="o">=</span> <span class="n">fastr</span><span class="o">.</span><span class="n">create_network</span><span class="p">(</span><span class="s1">&#39;WORC_GridSearch_&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span>
        <span class="n">estimator_data</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">create_source</span><span class="p">(</span><span class="s1">&#39;HDF5&#39;</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s1">&#39;estimator_source&#39;</span><span class="p">)</span>
        <span class="n">traintest_data</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">create_source</span><span class="p">(</span><span class="s1">&#39;HDF5&#39;</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s1">&#39;traintest&#39;</span><span class="p">)</span>
        <span class="n">parameter_data</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">create_source</span><span class="p">(</span><span class="s1">&#39;JsonFile&#39;</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s1">&#39;parameters&#39;</span><span class="p">)</span>
        <span class="n">sink_output</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">create_sink</span><span class="p">(</span><span class="s1">&#39;HDF5&#39;</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>

        <span class="n">fitandscore</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">create_node</span><span class="p">(</span><span class="s1">&#39;worc/fitandscore:1.0&#39;</span><span class="p">,</span> <span class="n">tool_version</span><span class="o">=</span><span class="s1">&#39;1.0&#39;</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s1">&#39;fitandscore&#39;</span><span class="p">,</span> <span class="n">resources</span><span class="o">=</span><span class="n">ResourceLimit</span><span class="p">(</span><span class="n">memory</span><span class="o">=</span><span class="s1">&#39;2G&#39;</span><span class="p">))</span>
        <span class="n">fitandscore</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;estimatordata&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">input_group</span> <span class="o">=</span> <span class="s1">&#39;estimator&#39;</span>
        <span class="n">fitandscore</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;traintest&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">input_group</span> <span class="o">=</span> <span class="s1">&#39;traintest&#39;</span>
        <span class="n">fitandscore</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">input_group</span> <span class="o">=</span> <span class="s1">&#39;parameters&#39;</span>

        <span class="n">fitandscore</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;estimatordata&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator_data</span><span class="o">.</span><span class="n">output</span>
        <span class="n">fitandscore</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;traintest&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traintest_data</span><span class="o">.</span><span class="n">output</span>
        <span class="n">fitandscore</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameter_data</span><span class="o">.</span><span class="n">output</span>
        <span class="n">sink_output</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">fitandscore</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;fittedestimator&#39;</span><span class="p">]</span>

        <span class="n">source_data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;estimator_source&#39;</span><span class="p">:</span> <span class="n">estimatordata</span><span class="p">,</span>
                       <span class="s1">&#39;traintest&#39;</span><span class="p">:</span> <span class="n">traintest_files</span><span class="p">,</span>
                       <span class="s1">&#39;parameters&#39;</span><span class="p">:</span> <span class="n">parameter_files</span><span class="p">}</span>
        <span class="n">sink_data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;vfs://tmp/GS/</span><span class="si">{name}</span><span class="s2">/output_{{sample_id}}_{{cardinality}}{{ext}}&quot;</span><span class="p">}</span>

        <span class="n">network</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">source_data</span><span class="p">,</span> <span class="n">sink_data</span><span class="p">,</span>
                        <span class="n">tmpdir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfolder</span><span class="p">,</span> <span class="s1">&#39;tmp&#39;</span><span class="p">),</span>
                        <span class="n">execution_plugin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fastr_plugin</span><span class="p">)</span>

        <span class="c1"># Read in the output data once finished</span>
        <span class="c1"># TODO: expanding fastr url is probably a nicer way</span>
        <span class="n">sink_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">fastr</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">mounts</span><span class="p">[</span><span class="s1">&#39;tmp&#39;</span><span class="p">],</span> <span class="s1">&#39;GS&#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;/output*.hdf5&#39;</span><span class="p">)</span>
        <span class="n">save_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">sink_files</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="n">save_data</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;RET&#39;</span><span class="p">]))</span>

        <span class="c1"># if one choose to see train score, &quot;out&quot; will contain train score info</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">:</span>
                <span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">test_sample_counts</span><span class="p">,</span>
                 <span class="n">fit_time</span><span class="p">,</span> <span class="n">score_time</span><span class="p">,</span> <span class="n">parameters_est</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">)</span> <span class="o">=</span>\
                  <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">save_data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">test_sample_counts</span><span class="p">,</span>
                 <span class="n">fit_time</span><span class="p">,</span> <span class="n">score_time</span><span class="p">,</span> <span class="n">parameters_est</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">)</span> <span class="o">=</span>\
                  <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">save_data</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="n">tempfolder</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfolder</span><span class="p">,</span> <span class="s1">&#39;tmp&#39;</span><span class="p">)</span>
            <span class="n">message</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;Fitting classifiers has failed. The temporary &#39;</span> <span class="o">+</span>
                       <span class="sa">f</span><span class="s1">&#39;results where not deleted and can be found in </span><span class="si">{tempfolder}</span><span class="s1">. &#39;</span> <span class="o">+</span>
                       <span class="s1">&#39;Probably your fitting and scoring failed: check out &#39;</span> <span class="o">+</span>
                       <span class="s1">&#39;the tmp/fitandscore folder within the tempfolder for &#39;</span> <span class="o">+</span>
                       <span class="s1">&#39;the fastr job temporary results or run: fastr trace &#39;</span> <span class="o">+</span>
                       <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{tmpfolder}{os.path.sep}</span><span class="s1">__sink_data__.json --samples.&#39;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">WORCexceptions</span><span class="o">.</span><span class="n">WORCValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

        <span class="c1"># Remove the temporary folder used</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">tempfolder</span><span class="p">)</span>

        <span class="c1"># Process the results of the fitting procedure</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">process_fit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
                         <span class="n">parameters_est</span><span class="o">=</span><span class="n">parameters_est</span><span class="p">,</span>
                         <span class="n">parameters_all</span><span class="o">=</span><span class="n">parameters_all</span><span class="p">,</span>
                         <span class="n">test_sample_counts</span><span class="o">=</span><span class="n">test_sample_counts</span><span class="p">,</span>
                         <span class="n">test_scores</span><span class="o">=</span><span class="n">test_scores</span><span class="p">,</span>
                         <span class="n">train_scores</span><span class="o">=</span><span class="n">train_scores</span><span class="p">,</span>
                         <span class="n">fit_time</span><span class="o">=</span><span class="n">fit_time</span><span class="p">,</span>
                         <span class="n">score_time</span><span class="o">=</span><span class="n">score_time</span><span class="p">,</span>
                         <span class="n">cv_iter</span><span class="o">=</span><span class="n">cv_iter</span><span class="p">,</span>
                         <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomizedSearchCVfastr"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.RandomizedSearchCVfastr">[docs]</a><span class="k">class</span> <span class="nc">RandomizedSearchCVfastr</span><span class="p">(</span><span class="n">BaseSearchCVfastr</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Randomized search on hyper parameters.</span>

<span class="sd">    RandomizedSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method.</span>
<span class="sd">    It also implements &quot;predict&quot;, &quot;predict_proba&quot;, &quot;decision_function&quot;,</span>
<span class="sd">    &quot;transform&quot; and &quot;inverse_transform&quot; if they are implemented in the</span>
<span class="sd">    estimator used.</span>

<span class="sd">    The parameters of the estimator used to apply these methods are optimized</span>
<span class="sd">    by cross-validated search over parameter settings.</span>

<span class="sd">    In contrast to GridSearchCV, not all parameter values are tried out, but</span>
<span class="sd">    rather a fixed number of parameter settings is sampled from the specified</span>
<span class="sd">    distributions. The number of parameter settings that are tried is</span>
<span class="sd">    given by n_iter.</span>

<span class="sd">    If all parameters are presented as a list,</span>
<span class="sd">    sampling without replacement is performed. If at least one parameter</span>
<span class="sd">    is given as a distribution, sampling with replacement is used.</span>
<span class="sd">    It is highly recommended to use continuous distributions for continuous</span>
<span class="sd">    parameters.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;randomized_parameter_search&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object.</span>
<span class="sd">        A object of that type is instantiated for each grid point.</span>
<span class="sd">        This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">        Either estimator needs to provide a ``score`` function,</span>
<span class="sd">        or ``scoring`` must be passed.</span>

<span class="sd">    param_distributions : dict</span>
<span class="sd">        Dictionary with parameters names (string) as keys and distributions</span>
<span class="sd">        or lists of parameters to try. Distributions must provide a ``rvs``</span>
<span class="sd">        method for sampling (such as those from scipy.stats.distributions).</span>
<span class="sd">        If a list is given, it is sampled uniformly.</span>

<span class="sd">    n_iter : int, default=10</span>
<span class="sd">        Number of parameter settings that are sampled. n_iter trades</span>
<span class="sd">        off runtime vs quality of the solution.</span>

<span class="sd">    scoring : string, callable or None, default=None</span>
<span class="sd">        A string (see model evaluation documentation) or</span>
<span class="sd">        a scorer callable object / function with signature</span>
<span class="sd">        ``scorer(estimator, X, y)``.</span>
<span class="sd">        If ``None``, the ``score`` method of the estimator is used.</span>

<span class="sd">    fit_params : dict, optional</span>
<span class="sd">        Parameters to pass to the fit method.</span>

<span class="sd">    n_jobs : int, default=1</span>
<span class="sd">        Number of jobs to run in parallel.</span>

<span class="sd">    pre_dispatch : int, or string, optional</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">            - None, in which case all the jobs are immediately</span>
<span class="sd">              created and spawned. Use this for lightweight and</span>
<span class="sd">              fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">              spawning of the jobs</span>

<span class="sd">            - An int, giving the exact number of total jobs that are</span>
<span class="sd">              spawned</span>

<span class="sd">            - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">              as in &#39;2*n_jobs&#39;</span>

<span class="sd">    iid : boolean, default=True</span>
<span class="sd">        If True, the data is assumed to be identically distributed across</span>
<span class="sd">        the folds, and the loss minimized is the total loss per sample,</span>
<span class="sd">        and not the mean loss across the folds.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>
<span class="sd">          - None, to use the default 3-fold cross validation,</span>
<span class="sd">          - integer, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">          - An object to be used as a cross-validation generator.</span>
<span class="sd">          - An iterable yielding train, test splits.</span>

<span class="sd">        For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">    refit : boolean, default=True</span>
<span class="sd">        Refit the best estimator with the entire dataset.</span>
<span class="sd">        If &quot;False&quot;, it is impossible to make predictions using</span>
<span class="sd">        this RandomizedSearchCV instance after fitting.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the verbosity: the higher, the more messages.</span>

<span class="sd">    random_state : int or RandomState</span>
<span class="sd">        Pseudo random number generator state used for random uniform sampling</span>
<span class="sd">        from lists of possible values instead of scipy.stats distributions.</span>

<span class="sd">    error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">        FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">        step, which will always raise the error.</span>

<span class="sd">    return_train_score : boolean, default=True</span>
<span class="sd">        If ``&#39;False&#39;``, the ``cv_results_`` attribute will not include training</span>
<span class="sd">        scores.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    cv_results_ : dict of numpy (masked) ndarrays</span>
<span class="sd">        A dict with keys as column headers and values as columns, that can be</span>
<span class="sd">        imported into a pandas ``DataFrame``.</span>

<span class="sd">        For instance the below given table</span>

<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        | param_kernel | param_gamma | split0_test_score |...|rank_test_score|</span>
<span class="sd">        +==============+=============+===================+===+===============+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.1     |        0.8        |...|       2       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.2     |        0.9        |...|       1       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.3     |        0.7        |...|       1       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>

<span class="sd">        will be represented by a ``cv_results_`` dict of::</span>

<span class="sd">            {</span>
<span class="sd">            &#39;param_kernel&#39; : masked_array(data = [&#39;rbf&#39;, &#39;rbf&#39;, &#39;rbf&#39;],</span>
<span class="sd">                                          mask = False),</span>
<span class="sd">            &#39;param_gamma&#39;  : masked_array(data = [0.1 0.2 0.3], mask = False),</span>
<span class="sd">            &#39;split0_test_score&#39;  : [0.8, 0.9, 0.7],</span>
<span class="sd">            &#39;split1_test_score&#39;  : [0.82, 0.5, 0.7],</span>
<span class="sd">            &#39;mean_test_score&#39;    : [0.81, 0.7, 0.7],</span>
<span class="sd">            &#39;std_test_score&#39;     : [0.02, 0.2, 0.],</span>
<span class="sd">            &#39;rank_test_score&#39;    : [3, 1, 1],</span>
<span class="sd">            &#39;split0_train_score&#39; : [0.8, 0.9, 0.7],</span>
<span class="sd">            &#39;split1_train_score&#39; : [0.82, 0.5, 0.7],</span>
<span class="sd">            &#39;mean_train_score&#39;   : [0.81, 0.7, 0.7],</span>
<span class="sd">            &#39;std_train_score&#39;    : [0.03, 0.03, 0.04],</span>
<span class="sd">            &#39;mean_fit_time&#39;      : [0.73, 0.63, 0.43, 0.49],</span>
<span class="sd">            &#39;std_fit_time&#39;       : [0.01, 0.02, 0.01, 0.01],</span>
<span class="sd">            &#39;mean_score_time&#39;    : [0.007, 0.06, 0.04, 0.04],</span>
<span class="sd">            &#39;std_score_time&#39;     : [0.001, 0.002, 0.003, 0.005],</span>
<span class="sd">            &#39;params&#39; : [{&#39;kernel&#39; : &#39;rbf&#39;, &#39;gamma&#39; : 0.1}, ...],</span>
<span class="sd">            }</span>

<span class="sd">        NOTE that the key ``&#39;params&#39;`` is used to store a list of parameter</span>
<span class="sd">        settings dict for all the parameter candidates.</span>

<span class="sd">        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and</span>
<span class="sd">        ``std_score_time`` are all in seconds.</span>

<span class="sd">    best_estimator_ : estimator</span>
<span class="sd">        Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">        which gave highest score (or smallest loss if specified)</span>
<span class="sd">        on the left out data. Not available if refit=False.</span>

<span class="sd">    best_score_ : float</span>
<span class="sd">        Score of best_estimator on the left out data.</span>

<span class="sd">    best_params_ : dict</span>
<span class="sd">        Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">    best_index_ : int</span>
<span class="sd">        The index (of the ``cv_results_`` arrays) which corresponds to the best</span>
<span class="sd">        candidate parameter setting.</span>

<span class="sd">        The dict at ``search.cv_results_[&#39;params&#39;][search.best_index_]`` gives</span>
<span class="sd">        the parameter setting for the best model, that gives the highest</span>
<span class="sd">        mean score (``search.best_score_``).</span>

<span class="sd">    scorer_ : function</span>
<span class="sd">        Scorer function used on the held out data to choose the best</span>
<span class="sd">        parameters for the model.</span>

<span class="sd">    n_splits_ : int</span>
<span class="sd">        The number of cross-validation splits (folds/iterations).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The parameters selected are those that maximize the score of the held-out</span>
<span class="sd">    data, according to the scoring parameter.</span>

<span class="sd">    If `n_jobs` was set to a value higher than one, the data is copied for each</span>
<span class="sd">    parameter setting(and not `n_jobs` times). This is done for efficiency</span>
<span class="sd">    reasons if individual jobs take very little time, but may raise errors if</span>
<span class="sd">    the dataset is large and not enough memory is available.  A workaround in</span>
<span class="sd">    this case is to set `pre_dispatch`. Then, the memory is copied only</span>
<span class="sd">    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *</span>
<span class="sd">    n_jobs`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    :class:`GridSearchCV`:</span>
<span class="sd">        Does exhaustive search over a grid of parameters.</span>

<span class="sd">    :class:`ParameterSampler`:</span>
<span class="sd">        A generator over parameter settings, constructed from</span>
<span class="sd">        param_distributions.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RandomizedSearchCVfastr.__init__"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.RandomizedSearchCVfastr.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="p">{},</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;2*n_jobs&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">error_score</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">n_jobspercore</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">fastr_plugin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">ranking_score</span><span class="o">=</span><span class="s1">&#39;test_score&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RandomizedSearchCVfastr</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
             <span class="n">param_distributions</span><span class="o">=</span><span class="n">param_distributions</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span>
             <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="n">iid</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="n">refit</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
             <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
             <span class="n">return_train_score</span><span class="o">=</span><span class="n">return_train_score</span><span class="p">,</span>
             <span class="n">n_jobspercore</span><span class="o">=</span><span class="n">n_jobspercore</span><span class="p">,</span> <span class="n">fastr_plugin</span><span class="o">=</span><span class="n">fastr_plugin</span><span class="p">,</span>
             <span class="n">maxlen</span><span class="o">=</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">ranking_score</span><span class="o">=</span><span class="n">ranking_score</span><span class="p">)</span></div>

<div class="viewcode-block" id="RandomizedSearchCVfastr.fit"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.RandomizedSearchCVfastr.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run fit on the estimator with randomly drawn parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape = [n_samples, n_features]</span>
<span class="sd">            Training vector, where n_samples in the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        y : array-like, shape = [n_samples] or [n_samples, n_output], optional</span>
<span class="sd">            Target relative to X for classification or regression;</span>
<span class="sd">            None for unsupervised learning.</span>

<span class="sd">        groups : array-like, with shape (n_samples,), optional</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fit: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">))</span>
        <span class="n">sampled_params</span> <span class="o">=</span> <span class="n">ParameterSampler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span>
                                          <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">sampled_params</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BaseSearchCVJoblib"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.BaseSearchCVJoblib">[docs]</a><span class="k">class</span> <span class="nc">BaseSearchCVJoblib</span><span class="p">(</span><span class="n">BaseSearchCV</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for hyper parameter search with cross-validation.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">parameter_iterable</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Actual fitting,  performing the search over parameters.&quot;&quot;&quot;</span>

        <span class="n">regressors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SVR&#39;</span><span class="p">,</span> <span class="s1">&#39;RFR&#39;</span><span class="p">,</span> <span class="s1">&#39;SGDR&#39;</span><span class="p">,</span> <span class="s1">&#39;Lasso&#39;</span><span class="p">,</span> <span class="s1">&#39;ElasticNet&#39;</span><span class="p">]</span>
        <span class="n">isclassifier</span> <span class="o">=</span>\
            <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">clf</span> <span class="ow">in</span> <span class="n">regressors</span> <span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">[</span><span class="s1">&#39;classifiers&#39;</span><span class="p">])</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">isclassifier</span><span class="p">)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameter_iterable</span><span class="p">,</span> <span class="n">Sized</span><span class="p">):</span>
            <span class="n">n_candidates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameter_iterable</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fitting </span><span class="si">{n_splits}</span><span class="s2"> folds for each of </span><span class="si">{n_candidates}</span><span class="s2">&quot;</span> <span class="o">+</span>\
                  <span class="s2">&quot; candidates, totalling&quot;</span> <span class="o">+</span>\
                  <span class="s2">&quot; {n_candidates * n_splits} fits&quot;</span><span class="p">)</span>

        <span class="n">pre_dispatch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_dispatch</span>
        <span class="n">cv_iter</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">))</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span>
        <span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">fit_and_score</span><span class="p">)(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span>
                                 <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span>
                                 <span class="n">fit_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_params</span><span class="p">,</span>
                                 <span class="n">return_train_score</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">,</span>
                                 <span class="n">return_n_test_samples</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">return_times</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_parameters</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">error_score</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">error_score</span><span class="p">,</span>
                                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                 <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">parameter_iterable</span>
          <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv_iter</span><span class="p">)</span>
        <span class="n">save_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># if one choose to see train score, &quot;out&quot; will contain train score info</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_train_score</span><span class="p">:</span>
            <span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">test_sample_counts</span><span class="p">,</span>
             <span class="n">fit_time</span><span class="p">,</span> <span class="n">score_time</span><span class="p">,</span> <span class="n">parameters_est</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">)</span> <span class="o">=</span>\
              <span class="n">save_data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">test_sample_counts</span><span class="p">,</span>
             <span class="n">fit_time</span><span class="p">,</span> <span class="n">score_time</span><span class="p">,</span> <span class="n">parameters_est</span><span class="p">,</span> <span class="n">parameters_all</span><span class="p">)</span> <span class="o">=</span>\
              <span class="n">save_data</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">process_fit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
                         <span class="n">parameters_est</span><span class="o">=</span><span class="n">parameters_est</span><span class="p">,</span>
                         <span class="n">parameters_all</span><span class="o">=</span><span class="n">parameters_all</span><span class="p">,</span>
                         <span class="n">test_sample_counts</span><span class="o">=</span><span class="n">test_sample_counts</span><span class="p">,</span>
                         <span class="n">test_scores</span><span class="o">=</span><span class="n">test_scores</span><span class="p">,</span>
                         <span class="n">train_scores</span><span class="o">=</span><span class="n">train_scores</span><span class="p">,</span>
                         <span class="n">fit_time</span><span class="o">=</span><span class="n">fit_time</span><span class="p">,</span>
                         <span class="n">score_time</span><span class="o">=</span><span class="n">score_time</span><span class="p">,</span>
                         <span class="n">cv_iter</span><span class="o">=</span><span class="n">cv_iter</span><span class="p">,</span>
                         <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="GridSearchCVfastr"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.GridSearchCVfastr">[docs]</a><span class="k">class</span> <span class="nc">GridSearchCVfastr</span><span class="p">(</span><span class="n">BaseSearchCVfastr</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Exhaustive search over specified parameter values for an estimator.</span>

<span class="sd">    Important members are fit, predict.</span>

<span class="sd">    GridSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method.</span>
<span class="sd">    It also implements &quot;predict&quot;, &quot;predict_proba&quot;, &quot;decision_function&quot;,</span>
<span class="sd">    &quot;transform&quot; and &quot;inverse_transform&quot; if they are implemented in the</span>
<span class="sd">    estimator used.</span>

<span class="sd">    The parameters of the estimator used to apply these methods are optimized</span>
<span class="sd">    by cross-validated grid-search over a parameter grid.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;grid_search&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object.</span>
<span class="sd">        This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">        Either estimator needs to provide a ``score`` function,</span>
<span class="sd">        or ``scoring`` must be passed.</span>

<span class="sd">    param_grid : dict or list of dictionaries</span>
<span class="sd">        Dictionary with parameters names (string) as keys and lists of</span>
<span class="sd">        parameter settings to try as values, or a list of such</span>
<span class="sd">        dictionaries, in which case the grids spanned by each dictionary</span>
<span class="sd">        in the list are explored. This enables searching over any sequence</span>
<span class="sd">        of parameter settings.</span>

<span class="sd">    scoring : string, callable or None, default=None</span>
<span class="sd">        A string (see model evaluation documentation) or</span>
<span class="sd">        a scorer callable object / function with signature</span>
<span class="sd">        ``scorer(estimator, X, y)``.</span>
<span class="sd">        If ``None``, the ``score`` method of the estimator is used.</span>

<span class="sd">    fit_params : dict, optional</span>
<span class="sd">        Parameters to pass to the fit method.</span>

<span class="sd">    n_jobs : int, default=1</span>
<span class="sd">        Number of jobs to run in parallel.</span>

<span class="sd">    pre_dispatch : int, or string, optional</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">            - None, in which case all the jobs are immediately</span>
<span class="sd">              created and spawned. Use this for lightweight and</span>
<span class="sd">              fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">              spawning of the jobs</span>

<span class="sd">            - An int, giving the exact number of total jobs that are</span>
<span class="sd">              spawned</span>

<span class="sd">            - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">              as in &#39;2*n_jobs&#39;</span>

<span class="sd">    iid : boolean, default=True</span>
<span class="sd">        If True, the data is assumed to be identically distributed across</span>
<span class="sd">        the folds, and the loss minimized is the total loss per sample,</span>
<span class="sd">        and not the mean loss across the folds.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>
<span class="sd">          - None, to use the default 3-fold cross validation,</span>
<span class="sd">          - integer, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">          - An object to be used as a cross-validation generator.</span>
<span class="sd">          - An iterable yielding train, test splits.</span>

<span class="sd">        For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">    refit : boolean, default=True</span>
<span class="sd">        Refit the best estimator with the entire dataset.</span>
<span class="sd">        If &quot;False&quot;, it is impossible to make predictions using</span>
<span class="sd">        this GridSearchCV instance after fitting.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the verbosity: the higher, the more messages.</span>

<span class="sd">    error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">        FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">        step, which will always raise the error.</span>

<span class="sd">    return_train_score : boolean, default=True</span>
<span class="sd">        If ``&#39;False&#39;``, the ``cv_results_`` attribute will not include training</span>
<span class="sd">        scores.</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import svm, datasets</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import GridSearchCV</span>
<span class="sd">    &gt;&gt;&gt; iris = datasets.load_iris()</span>
<span class="sd">    &gt;&gt;&gt; parameters = {&#39;kernel&#39;:(&#39;linear&#39;, &#39;rbf&#39;), &#39;C&#39;:[1, 10]}</span>
<span class="sd">    &gt;&gt;&gt; svr = svm.SVC()</span>
<span class="sd">    &gt;&gt;&gt; clf = GridSearchCV(svr, parameters)</span>
<span class="sd">    &gt;&gt;&gt; clf.fit(iris.data, iris.target)</span>
<span class="sd">    ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS</span>
<span class="sd">    GridSearchCV(cv=None, error_score=...,</span>
<span class="sd">           estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,</span>
<span class="sd">                         decision_function_shape=None, degree=..., gamma=...,</span>
<span class="sd">                         kernel=&#39;rbf&#39;, max_iter=-1, probability=False,</span>
<span class="sd">                         random_state=None, shrinking=True, tol=...,</span>
<span class="sd">                         verbose=False),</span>
<span class="sd">           fit_params={}, iid=..., n_jobs=1,</span>
<span class="sd">           param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,</span>
<span class="sd">           scoring=..., verbose=...)</span>
<span class="sd">    &gt;&gt;&gt; sorted(clf.cv_results_.keys())</span>
<span class="sd">    ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS</span>
<span class="sd">    [&#39;mean_fit_time&#39;, &#39;mean_score_time&#39;, &#39;mean_test_score&#39;,...</span>
<span class="sd">     &#39;mean_train_score&#39;, &#39;param_C&#39;, &#39;param_kernel&#39;, &#39;params&#39;,...</span>
<span class="sd">     &#39;rank_test_score&#39;, &#39;split0_test_score&#39;,...</span>
<span class="sd">     &#39;split0_train_score&#39;, &#39;split1_test_score&#39;, &#39;split1_train_score&#39;,...</span>
<span class="sd">     &#39;split2_test_score&#39;, &#39;split2_train_score&#39;,...</span>
<span class="sd">     &#39;std_fit_time&#39;, &#39;std_score_time&#39;, &#39;std_test_score&#39;, &#39;std_train_score&#39;...]</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    cv_results_ : dict of numpy (masked) ndarrays</span>
<span class="sd">        A dict with keys as column headers and values as columns, that can be</span>
<span class="sd">        imported into a pandas ``DataFrame``.</span>

<span class="sd">        For instance the below given table</span>

<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_....|</span>
<span class="sd">        +============+===========+============+=================+===+=========+</span>
<span class="sd">        |  &#39;poly&#39;    |     --    |      2     |        0.8      |...|    2    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;poly&#39;    |     --    |      3     |        0.7      |...|    4    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;rbf&#39;     |     0.1   |     --     |        0.8      |...|    3    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;rbf&#39;     |     0.2   |     --     |        0.9      |...|    1    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>

<span class="sd">        will be represented by a ``cv_results_`` dict of::</span>

<span class="sd">            {</span>
<span class="sd">            &#39;param_kernel&#39;: masked_array(data = [&#39;poly&#39;, &#39;poly&#39;, &#39;rbf&#39;, &#39;rbf&#39;],</span>
<span class="sd">                                         mask = [False False False False]...)</span>
<span class="sd">            &#39;param_gamma&#39;: masked_array(data = [-- -- 0.1 0.2],</span>
<span class="sd">                                        mask = [ True  True False False]...),</span>
<span class="sd">            &#39;param_degree&#39;: masked_array(data = [2.0 3.0 -- --],</span>
<span class="sd">                                         mask = [False False  True  True]...),</span>
<span class="sd">            &#39;split0_test_score&#39;  : [0.8, 0.7, 0.8, 0.9],</span>
<span class="sd">            &#39;split1_test_score&#39;  : [0.82, 0.5, 0.7, 0.78],</span>
<span class="sd">            &#39;mean_test_score&#39;    : [0.81, 0.60, 0.75, 0.82],</span>
<span class="sd">            &#39;std_test_score&#39;     : [0.02, 0.01, 0.03, 0.03],</span>
<span class="sd">            &#39;rank_test_score&#39;    : [2, 4, 3, 1],</span>
<span class="sd">            &#39;split0_train_score&#39; : [0.8, 0.9, 0.7],</span>
<span class="sd">            &#39;split1_train_score&#39; : [0.82, 0.5, 0.7],</span>
<span class="sd">            &#39;mean_train_score&#39;   : [0.81, 0.7, 0.7],</span>
<span class="sd">            &#39;std_train_score&#39;    : [0.03, 0.03, 0.04],</span>
<span class="sd">            &#39;mean_fit_time&#39;      : [0.73, 0.63, 0.43, 0.49],</span>
<span class="sd">            &#39;std_fit_time&#39;       : [0.01, 0.02, 0.01, 0.01],</span>
<span class="sd">            &#39;mean_score_time&#39;    : [0.007, 0.06, 0.04, 0.04],</span>
<span class="sd">            &#39;std_score_time&#39;     : [0.001, 0.002, 0.003, 0.005],</span>
<span class="sd">            &#39;params&#39;             : [{&#39;kernel&#39;: &#39;poly&#39;, &#39;degree&#39;: 2}, ...],</span>
<span class="sd">            }</span>

<span class="sd">        NOTE that the key ``&#39;params&#39;`` is used to store a list of parameter</span>
<span class="sd">        settings dict for all the parameter candidates.</span>

<span class="sd">        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and</span>
<span class="sd">        ``std_score_time`` are all in seconds.</span>

<span class="sd">    best_estimator_ : estimator</span>
<span class="sd">        Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">        which gave highest score (or smallest loss if specified)</span>
<span class="sd">        on the left out data. Not available if refit=False.</span>

<span class="sd">    best_score_ : float</span>
<span class="sd">        Score of best_estimator on the left out data.</span>

<span class="sd">    best_params_ : dict</span>
<span class="sd">        Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">    best_index_ : int</span>
<span class="sd">        The index (of the ``cv_results_`` arrays) which corresponds to the best</span>
<span class="sd">        candidate parameter setting.</span>

<span class="sd">        The dict at ``search.cv_results_[&#39;params&#39;][search.best_index_]`` gives</span>
<span class="sd">        the parameter setting for the best model, that gives the highest</span>
<span class="sd">        mean score (``search.best_score_``).</span>

<span class="sd">    scorer_ : function</span>
<span class="sd">        Scorer function used on the held out data to choose the best</span>
<span class="sd">        parameters for the model.</span>

<span class="sd">    n_splits_ : int</span>
<span class="sd">        The number of cross-validation splits (folds/iterations).</span>

<span class="sd">    Notes</span>
<span class="sd">    ------</span>
<span class="sd">    The parameters selected are those that maximize the score of the left out</span>
<span class="sd">    data, unless an explicit score is passed in which case it is used instead.</span>

<span class="sd">    If `n_jobs` was set to a value higher than one, the data is copied for each</span>
<span class="sd">    point in the grid (and not `n_jobs` times). This is done for efficiency</span>
<span class="sd">    reasons if individual jobs take very little time, but may raise errors if</span>
<span class="sd">    the dataset is large and not enough memory is available.  A workaround in</span>
<span class="sd">    this case is to set `pre_dispatch`. Then, the memory is copied only</span>
<span class="sd">    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *</span>
<span class="sd">    n_jobs`.</span>

<span class="sd">    See Also</span>
<span class="sd">    ---------</span>
<span class="sd">    :class:`ParameterGrid`:</span>
<span class="sd">        generates all the combinations of a hyperparameter grid.</span>

<span class="sd">    :func:`sklearn.model_selection.train_test_split`:</span>
<span class="sd">        utility function to split the data into a development set usable</span>
<span class="sd">        for fitting a GridSearchCV instance and an evaluation set for</span>
<span class="sd">        its final evaluation.</span>

<span class="sd">    :func:`sklearn.metrics.make_scorer`:</span>
<span class="sd">        Make a scorer from a performance metric or loss function.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GridSearchCVfastr.__init__"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.GridSearchCVfastr.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;2*n_jobs&#39;</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">,</span>
                 <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GridSearchCVfastr</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="n">iid</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="n">refit</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="n">return_train_score</span><span class="p">,</span> <span class="n">fastr_plugin</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
        <span class="n">_check_param_grid</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span></div>

<div class="viewcode-block" id="GridSearchCVfastr.fit"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.GridSearchCVfastr.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run fit with all sets of parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X : array-like, shape = [n_samples, n_features]</span>
<span class="sd">            Training vector, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        y : array-like, shape = [n_samples] or [n_samples, n_output], optional</span>
<span class="sd">            Target relative to X for classification or regression;</span>
<span class="sd">            None for unsupervised learning.</span>

<span class="sd">        groups : array-like, with shape (n_samples,), optional</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">ParameterGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="RandomizedSearchCVJoblib"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.RandomizedSearchCVJoblib">[docs]</a><span class="k">class</span> <span class="nc">RandomizedSearchCVJoblib</span><span class="p">(</span><span class="n">BaseSearchCVJoblib</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Randomized search on hyper parameters.</span>

<span class="sd">    RandomizedSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method.</span>
<span class="sd">    It also implements &quot;predict&quot;, &quot;predict_proba&quot;, &quot;decision_function&quot;,</span>
<span class="sd">    &quot;transform&quot; and &quot;inverse_transform&quot; if they are implemented in the</span>
<span class="sd">    estimator used.</span>

<span class="sd">    The parameters of the estimator used to apply these methods are optimized</span>
<span class="sd">    by cross-validated search over parameter settings.</span>

<span class="sd">    In contrast to GridSearchCV, not all parameter values are tried out, but</span>
<span class="sd">    rather a fixed number of parameter settings is sampled from the specified</span>
<span class="sd">    distributions. The number of parameter settings that are tried is</span>
<span class="sd">    given by n_iter.</span>

<span class="sd">    If all parameters are presented as a list,</span>
<span class="sd">    sampling without replacement is performed. If at least one parameter</span>
<span class="sd">    is given as a distribution, sampling with replacement is used.</span>
<span class="sd">    It is highly recommended to use continuous distributions for continuous</span>
<span class="sd">    parameters.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;randomized_parameter_search&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object.</span>
<span class="sd">        A object of that type is instantiated for each grid point.</span>
<span class="sd">        This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">        Either estimator needs to provide a ``score`` function,</span>
<span class="sd">        or ``scoring`` must be passed.</span>

<span class="sd">    param_distributions : dict</span>
<span class="sd">        Dictionary with parameters names (string) as keys and distributions</span>
<span class="sd">        or lists of parameters to try. Distributions must provide a ``rvs``</span>
<span class="sd">        method for sampling (such as those from scipy.stats.distributions).</span>
<span class="sd">        If a list is given, it is sampled uniformly.</span>

<span class="sd">    n_iter : int, default=10</span>
<span class="sd">        Number of parameter settings that are sampled. n_iter trades</span>
<span class="sd">        off runtime vs quality of the solution.</span>

<span class="sd">    scoring : string, callable or None, default=None</span>
<span class="sd">        A string (see model evaluation documentation) or</span>
<span class="sd">        a scorer callable object / function with signature</span>
<span class="sd">        ``scorer(estimator, X, y)``.</span>
<span class="sd">        If ``None``, the ``score`` method of the estimator is used.</span>

<span class="sd">    fit_params : dict, optional</span>
<span class="sd">        Parameters to pass to the fit method.</span>

<span class="sd">    n_jobs : int, default=1</span>
<span class="sd">        Number of jobs to run in parallel.</span>

<span class="sd">    pre_dispatch : int, or string, optional</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">            - None, in which case all the jobs are immediately</span>
<span class="sd">              created and spawned. Use this for lightweight and</span>
<span class="sd">              fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">              spawning of the jobs</span>

<span class="sd">            - An int, giving the exact number of total jobs that are</span>
<span class="sd">              spawned</span>

<span class="sd">            - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">              as in &#39;2*n_jobs&#39;</span>

<span class="sd">    iid : boolean, default=True</span>
<span class="sd">        If True, the data is assumed to be identically distributed across</span>
<span class="sd">        the folds, and the loss minimized is the total loss per sample,</span>
<span class="sd">        and not the mean loss across the folds.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>
<span class="sd">          - None, to use the default 3-fold cross validation,</span>
<span class="sd">          - integer, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">          - An object to be used as a cross-validation generator.</span>
<span class="sd">          - An iterable yielding train, test splits.</span>

<span class="sd">        For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">    refit : boolean, default=True</span>
<span class="sd">        Refit the best estimator with the entire dataset.</span>
<span class="sd">        If &quot;False&quot;, it is impossible to make predictions using</span>
<span class="sd">        this RandomizedSearchCV instance after fitting.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the verbosity: the higher, the more messages.</span>

<span class="sd">    random_state : int or RandomState</span>
<span class="sd">        Pseudo random number generator state used for random uniform sampling</span>
<span class="sd">        from lists of possible values instead of scipy.stats distributions.</span>

<span class="sd">    error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">        FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">        step, which will always raise the error.</span>

<span class="sd">    return_train_score : boolean, default=True</span>
<span class="sd">        If ``&#39;False&#39;``, the ``cv_results_`` attribute will not include training</span>
<span class="sd">        scores.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    cv_results_ : dict of numpy (masked) ndarrays</span>
<span class="sd">        A dict with keys as column headers and values as columns, that can be</span>
<span class="sd">        imported into a pandas ``DataFrame``.</span>

<span class="sd">        For instance the below given table</span>

<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        | param_kernel | param_gamma | split0_test_score |...|rank_test_score|</span>
<span class="sd">        +==============+=============+===================+===+===============+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.1     |        0.8        |...|       2       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.2     |        0.9        |...|       1       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">        |    &#39;rbf&#39;     |     0.3     |        0.7        |...|       1       |</span>
<span class="sd">        +--------------+-------------+-------------------+---+---------------+</span>

<span class="sd">        will be represented by a ``cv_results_`` dict of::</span>

<span class="sd">            {</span>
<span class="sd">            &#39;param_kernel&#39; : masked_array(data = [&#39;rbf&#39;, &#39;rbf&#39;, &#39;rbf&#39;],</span>
<span class="sd">                                          mask = False),</span>
<span class="sd">            &#39;param_gamma&#39;  : masked_array(data = [0.1 0.2 0.3], mask = False),</span>
<span class="sd">            &#39;split0_test_score&#39;  : [0.8, 0.9, 0.7],</span>
<span class="sd">            &#39;split1_test_score&#39;  : [0.82, 0.5, 0.7],</span>
<span class="sd">            &#39;mean_test_score&#39;    : [0.81, 0.7, 0.7],</span>
<span class="sd">            &#39;std_test_score&#39;     : [0.02, 0.2, 0.],</span>
<span class="sd">            &#39;rank_test_score&#39;    : [3, 1, 1],</span>
<span class="sd">            &#39;split0_train_score&#39; : [0.8, 0.9, 0.7],</span>
<span class="sd">            &#39;split1_train_score&#39; : [0.82, 0.5, 0.7],</span>
<span class="sd">            &#39;mean_train_score&#39;   : [0.81, 0.7, 0.7],</span>
<span class="sd">            &#39;std_train_score&#39;    : [0.03, 0.03, 0.04],</span>
<span class="sd">            &#39;mean_fit_time&#39;      : [0.73, 0.63, 0.43, 0.49],</span>
<span class="sd">            &#39;std_fit_time&#39;       : [0.01, 0.02, 0.01, 0.01],</span>
<span class="sd">            &#39;mean_score_time&#39;    : [0.007, 0.06, 0.04, 0.04],</span>
<span class="sd">            &#39;std_score_time&#39;     : [0.001, 0.002, 0.003, 0.005],</span>
<span class="sd">            &#39;params&#39; : [{&#39;kernel&#39; : &#39;rbf&#39;, &#39;gamma&#39; : 0.1}, ...],</span>
<span class="sd">            }</span>

<span class="sd">        NOTE that the key ``&#39;params&#39;`` is used to store a list of parameter</span>
<span class="sd">        settings dict for all the parameter candidates.</span>

<span class="sd">        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and</span>
<span class="sd">        ``std_score_time`` are all in seconds.</span>

<span class="sd">    best_estimator_ : estimator</span>
<span class="sd">        Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">        which gave highest score (or smallest loss if specified)</span>
<span class="sd">        on the left out data. Not available if refit=False.</span>

<span class="sd">    best_score_ : float</span>
<span class="sd">        Score of best_estimator on the left out data.</span>

<span class="sd">    best_params_ : dict</span>
<span class="sd">        Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">    best_index_ : int</span>
<span class="sd">        The index (of the ``cv_results_`` arrays) which corresponds to the best</span>
<span class="sd">        candidate parameter setting.</span>

<span class="sd">        The dict at ``search.cv_results_[&#39;params&#39;][search.best_index_]`` gives</span>
<span class="sd">        the parameter setting for the best model, that gives the highest</span>
<span class="sd">        mean score (``search.best_score_``).</span>

<span class="sd">    scorer_ : function</span>
<span class="sd">        Scorer function used on the held out data to choose the best</span>
<span class="sd">        parameters for the model.</span>

<span class="sd">    n_splits_ : int</span>
<span class="sd">        The number of cross-validation splits (folds/iterations).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The parameters selected are those that maximize the score of the held-out</span>
<span class="sd">    data, according to the scoring parameter.</span>

<span class="sd">    If `n_jobs` was set to a value higher than one, the data is copied for each</span>
<span class="sd">    parameter setting(and not `n_jobs` times). This is done for efficiency</span>
<span class="sd">    reasons if individual jobs take very little time, but may raise errors if</span>
<span class="sd">    the dataset is large and not enough memory is available.  A workaround in</span>
<span class="sd">    this case is to set `pre_dispatch`. Then, the memory is copied only</span>
<span class="sd">    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *</span>
<span class="sd">    n_jobs`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    :class:`GridSearchCV`:</span>
<span class="sd">        Does exhaustive search over a grid of parameters.</span>

<span class="sd">    :class:`ParameterSampler`:</span>
<span class="sd">        A generator over parameter settins, constructed from</span>
<span class="sd">        param_distributions.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RandomizedSearchCVJoblib.__init__"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.RandomizedSearchCVJoblib.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="p">{},</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;2*n_jobs&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">error_score</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">n_jobspercore</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">ranking_score</span><span class="o">=</span><span class="s1">&#39;test_score&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RandomizedSearchCVJoblib</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
             <span class="n">param_distributions</span><span class="o">=</span><span class="n">param_distributions</span><span class="p">,</span>
             <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span>
             <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="n">iid</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="n">refit</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
             <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
             <span class="n">return_train_score</span><span class="o">=</span><span class="n">return_train_score</span><span class="p">,</span>
             <span class="n">n_jobspercore</span><span class="o">=</span><span class="n">n_jobspercore</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
             <span class="n">maxlen</span><span class="o">=</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">ranking_score</span><span class="o">=</span><span class="n">ranking_score</span><span class="p">)</span></div>

<div class="viewcode-block" id="RandomizedSearchCVJoblib.fit"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.RandomizedSearchCVJoblib.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run fit on the estimator with randomly drawn parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape = [n_samples, n_features]</span>
<span class="sd">            Training vector, where n_samples in the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        y : array-like, shape = [n_samples] or [n_samples, n_output], optional</span>
<span class="sd">            Target relative to X for classification or regression;</span>
<span class="sd">            None for unsupervised learning.</span>

<span class="sd">        groups : array-like, with shape (n_samples,), optional</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sampled_params</span> <span class="o">=</span> <span class="n">ParameterSampler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span>
                                          <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">sampled_params</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="GridSearchCVJoblib"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.GridSearchCVJoblib">[docs]</a><span class="k">class</span> <span class="nc">GridSearchCVJoblib</span><span class="p">(</span><span class="n">BaseSearchCVJoblib</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Exhaustive search over specified parameter values for an estimator.</span>

<span class="sd">    Important members are fit, predict.</span>

<span class="sd">    GridSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method.</span>
<span class="sd">    It also implements &quot;predict&quot;, &quot;predict_proba&quot;, &quot;decision_function&quot;,</span>
<span class="sd">    &quot;transform&quot; and &quot;inverse_transform&quot; if they are implemented in the</span>
<span class="sd">    estimator used.</span>

<span class="sd">    The parameters of the estimator used to apply these methods are optimized</span>
<span class="sd">    by cross-validated grid-search over a parameter grid.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;grid_search&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object.</span>
<span class="sd">        This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">        Either estimator needs to provide a ``score`` function,</span>
<span class="sd">        or ``scoring`` must be passed.</span>

<span class="sd">    param_grid : dict or list of dictionaries</span>
<span class="sd">        Dictionary with parameters names (string) as keys and lists of</span>
<span class="sd">        parameter settings to try as values, or a list of such</span>
<span class="sd">        dictionaries, in which case the grids spanned by each dictionary</span>
<span class="sd">        in the list are explored. This enables searching over any sequence</span>
<span class="sd">        of parameter settings.</span>

<span class="sd">    scoring : string, callable or None, default=None</span>
<span class="sd">        A string (see model evaluation documentation) or</span>
<span class="sd">        a scorer callable object / function with signature</span>
<span class="sd">        ``scorer(estimator, X, y)``.</span>
<span class="sd">        If ``None``, the ``score`` method of the estimator is used.</span>

<span class="sd">    fit_params : dict, optional</span>
<span class="sd">        Parameters to pass to the fit method.</span>

<span class="sd">    n_jobs : int, default=1</span>
<span class="sd">        Number of jobs to run in parallel.</span>

<span class="sd">    pre_dispatch : int, or string, optional</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">            - None, in which case all the jobs are immediately</span>
<span class="sd">              created and spawned. Use this for lightweight and</span>
<span class="sd">              fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">              spawning of the jobs</span>

<span class="sd">            - An int, giving the exact number of total jobs that are</span>
<span class="sd">              spawned</span>

<span class="sd">            - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">              as in &#39;2*n_jobs&#39;</span>

<span class="sd">    iid : boolean, default=True</span>
<span class="sd">        If True, the data is assumed to be identically distributed across</span>
<span class="sd">        the folds, and the loss minimized is the total loss per sample,</span>
<span class="sd">        and not the mean loss across the folds.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>
<span class="sd">          - None, to use the default 3-fold cross validation,</span>
<span class="sd">          - integer, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">          - An object to be used as a cross-validation generator.</span>
<span class="sd">          - An iterable yielding train, test splits.</span>

<span class="sd">        For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">    refit : boolean, default=True</span>
<span class="sd">        Refit the best estimator with the entire dataset.</span>
<span class="sd">        If &quot;False&quot;, it is impossible to make predictions using</span>
<span class="sd">        this GridSearchCV instance after fitting.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        Controls the verbosity: the higher, the more messages.</span>

<span class="sd">    error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">        FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">        step, which will always raise the error.</span>

<span class="sd">    return_train_score : boolean, default=True</span>
<span class="sd">        If ``&#39;False&#39;``, the ``cv_results_`` attribute will not include training</span>
<span class="sd">        scores.</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import svm, datasets</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import GridSearchCV</span>
<span class="sd">    &gt;&gt;&gt; iris = datasets.load_iris()</span>
<span class="sd">    &gt;&gt;&gt; parameters = {&#39;kernel&#39;:(&#39;linear&#39;, &#39;rbf&#39;), &#39;C&#39;:[1, 10]}</span>
<span class="sd">    &gt;&gt;&gt; svr = svm.SVC()</span>
<span class="sd">    &gt;&gt;&gt; clf = GridSearchCV(svr, parameters)</span>
<span class="sd">    &gt;&gt;&gt; clf.fit(iris.data, iris.target)</span>
<span class="sd">    ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS</span>
<span class="sd">    GridSearchCV(cv=None, error_score=...,</span>
<span class="sd">           estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,</span>
<span class="sd">                         decision_function_shape=None, degree=..., gamma=...,</span>
<span class="sd">                         kernel=&#39;rbf&#39;, max_iter=-1, probability=False,</span>
<span class="sd">                         random_state=None, shrinking=True, tol=...,</span>
<span class="sd">                         verbose=False),</span>
<span class="sd">           fit_params={}, iid=..., n_jobs=1,</span>
<span class="sd">           param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,</span>
<span class="sd">           scoring=..., verbose=...)</span>
<span class="sd">    &gt;&gt;&gt; sorted(clf.cv_results_.keys())</span>
<span class="sd">    ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS</span>
<span class="sd">    [&#39;mean_fit_time&#39;, &#39;mean_score_time&#39;, &#39;mean_test_score&#39;,...</span>
<span class="sd">     &#39;mean_train_score&#39;, &#39;param_C&#39;, &#39;param_kernel&#39;, &#39;params&#39;,...</span>
<span class="sd">     &#39;rank_test_score&#39;, &#39;split0_test_score&#39;,...</span>
<span class="sd">     &#39;split0_train_score&#39;, &#39;split1_test_score&#39;, &#39;split1_train_score&#39;,...</span>
<span class="sd">     &#39;split2_test_score&#39;, &#39;split2_train_score&#39;,...</span>
<span class="sd">     &#39;std_fit_time&#39;, &#39;std_score_time&#39;, &#39;std_test_score&#39;, &#39;std_train_score&#39;...]</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    cv_results_ : dict of numpy (masked) ndarrays</span>
<span class="sd">        A dict with keys as column headers and values as columns, that can be</span>
<span class="sd">        imported into a pandas ``DataFrame``.</span>

<span class="sd">        For instance the below given table</span>

<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_....|</span>
<span class="sd">        +============+===========+============+=================+===+=========+</span>
<span class="sd">        |  &#39;poly&#39;    |     --    |      2     |        0.8      |...|    2    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;poly&#39;    |     --    |      3     |        0.7      |...|    4    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;rbf&#39;     |     0.1   |     --     |        0.8      |...|    3    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">        |  &#39;rbf&#39;     |     0.2   |     --     |        0.9      |...|    1    |</span>
<span class="sd">        +------------+-----------+------------+-----------------+---+---------+</span>

<span class="sd">        will be represented by a ``cv_results_`` dict of::</span>

<span class="sd">            {</span>
<span class="sd">            &#39;param_kernel&#39;: masked_array(data = [&#39;poly&#39;, &#39;poly&#39;, &#39;rbf&#39;, &#39;rbf&#39;],</span>
<span class="sd">                                         mask = [False False False False]...)</span>
<span class="sd">            &#39;param_gamma&#39;: masked_array(data = [-- -- 0.1 0.2],</span>
<span class="sd">                                        mask = [ True  True False False]...),</span>
<span class="sd">            &#39;param_degree&#39;: masked_array(data = [2.0 3.0 -- --],</span>
<span class="sd">                                         mask = [False False  True  True]...),</span>
<span class="sd">            &#39;split0_test_score&#39;  : [0.8, 0.7, 0.8, 0.9],</span>
<span class="sd">            &#39;split1_test_score&#39;  : [0.82, 0.5, 0.7, 0.78],</span>
<span class="sd">            &#39;mean_test_score&#39;    : [0.81, 0.60, 0.75, 0.82],</span>
<span class="sd">            &#39;std_test_score&#39;     : [0.02, 0.01, 0.03, 0.03],</span>
<span class="sd">            &#39;rank_test_score&#39;    : [2, 4, 3, 1],</span>
<span class="sd">            &#39;split0_train_score&#39; : [0.8, 0.9, 0.7],</span>
<span class="sd">            &#39;split1_train_score&#39; : [0.82, 0.5, 0.7],</span>
<span class="sd">            &#39;mean_train_score&#39;   : [0.81, 0.7, 0.7],</span>
<span class="sd">            &#39;std_train_score&#39;    : [0.03, 0.03, 0.04],</span>
<span class="sd">            &#39;mean_fit_time&#39;      : [0.73, 0.63, 0.43, 0.49],</span>
<span class="sd">            &#39;std_fit_time&#39;       : [0.01, 0.02, 0.01, 0.01],</span>
<span class="sd">            &#39;mean_score_time&#39;    : [0.007, 0.06, 0.04, 0.04],</span>
<span class="sd">            &#39;std_score_time&#39;     : [0.001, 0.002, 0.003, 0.005],</span>
<span class="sd">            &#39;params&#39;             : [{&#39;kernel&#39;: &#39;poly&#39;, &#39;degree&#39;: 2}, ...],</span>
<span class="sd">            }</span>

<span class="sd">        NOTE that the key ``&#39;params&#39;`` is used to store a list of parameter</span>
<span class="sd">        settings dict for all the parameter candidates.</span>

<span class="sd">        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and</span>
<span class="sd">        ``std_score_time`` are all in seconds.</span>

<span class="sd">    best_estimator_ : estimator</span>
<span class="sd">        Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">        which gave highest score (or smallest loss if specified)</span>
<span class="sd">        on the left out data. Not available if refit=False.</span>

<span class="sd">    best_score_ : float</span>
<span class="sd">        Score of best_estimator on the left out data.</span>

<span class="sd">    best_params_ : dict</span>
<span class="sd">        Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">    best_index_ : int</span>
<span class="sd">        The index (of the ``cv_results_`` arrays) which corresponds to the best</span>
<span class="sd">        candidate parameter setting.</span>

<span class="sd">        The dict at ``search.cv_results_[&#39;params&#39;][search.best_index_]`` gives</span>
<span class="sd">        the parameter setting for the best model, that gives the highest</span>
<span class="sd">        mean score (``search.best_score_``).</span>

<span class="sd">    scorer_ : function</span>
<span class="sd">        Scorer function used on the held out data to choose the best</span>
<span class="sd">        parameters for the model.</span>

<span class="sd">    n_splits_ : int</span>
<span class="sd">        The number of cross-validation splits (folds/iterations).</span>

<span class="sd">    Notes</span>
<span class="sd">    ------</span>
<span class="sd">    The parameters selected are those that maximize the score of the left out</span>
<span class="sd">    data, unless an explicit score is passed in which case it is used instead.</span>

<span class="sd">    If `n_jobs` was set to a value higher than one, the data is copied for each</span>
<span class="sd">    point in the grid (and not `n_jobs` times). This is done for efficiency</span>
<span class="sd">    reasons if individual jobs take very little time, but may raise errors if</span>
<span class="sd">    the dataset is large and not enough memory is available.  A workaround in</span>
<span class="sd">    this case is to set `pre_dispatch`. Then, the memory is copied only</span>
<span class="sd">    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *</span>
<span class="sd">    n_jobs`.</span>

<span class="sd">    See Also</span>
<span class="sd">    ---------</span>
<span class="sd">    :class:`ParameterGrid`:</span>
<span class="sd">        generates all the combinations of a hyperparameter grid.</span>

<span class="sd">    :func:`sklearn.model_selection.train_test_split`:</span>
<span class="sd">        utility function to split the data into a development set usable</span>
<span class="sd">        for fitting a GridSearchCV instance and an evaluation set for</span>
<span class="sd">        its final evaluation.</span>

<span class="sd">    :func:`sklearn.metrics.make_scorer`:</span>
<span class="sd">        Make a scorer from a performance metric or loss function.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GridSearchCVJoblib.__init__"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.GridSearchCVJoblib.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;2*n_jobs&#39;</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">,</span>
                 <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GridSearchCVJoblib</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">iid</span><span class="o">=</span><span class="n">iid</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="n">refit</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="n">return_train_score</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
        <span class="n">_check_param_grid</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span></div>

<div class="viewcode-block" id="GridSearchCVJoblib.fit"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.SearchCV.GridSearchCVJoblib.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run fit with all sets of parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        X : array-like, shape = [n_samples, n_features]</span>
<span class="sd">            Training vector, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        y : array-like, shape = [n_samples] or [n_samples, n_output], optional</span>
<span class="sd">            Target relative to X for classification or regression;</span>
<span class="sd">            None for unsupervised learning.</span>

<span class="sd">        groups : array-like, with shape (n_samples,), optional</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">ParameterGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">))</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016 -- 2019, Biomedical Imaging Group Rotterdam, Departments of Medical Informatics and Radiology, Erasmus MC, Rotterdam, The Netherlands

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>