

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>WORC.classification.fitandscore &mdash; WORC 3.3.5 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> WORC
          

          
            
            <img src="../../../_static/WORC_Logo.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                3.3.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../static/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/quick_start.html">Quick start guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/user_manual.html">User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/features.html">Radiomics Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/additionalfunctionality.html">Additional functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/developerdocumentation.html">Developer documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/file_description.html">Resource File Formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../static/changelog.html">Changelog</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../autogen/WORC.html">WORC Package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">WORC</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>WORC.classification.fitandscore</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for WORC.classification.fitandscore</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>

<span class="c1"># Copyright 2016-2020 Biomedical Imaging Group Rotterdam, Departments of</span>
<span class="c1"># Medical Informatics and Radiology, Erasmus MC, Rotterdam, The Netherlands</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection._validation</span> <span class="k">import</span> <span class="n">_fit_and_score</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectFromModel</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.multiclass</span> <span class="k">import</span> <span class="n">OneVsRestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">WORC.classification.ObjectSampler</span> <span class="k">import</span> <span class="n">ObjectSampler</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.metaestimators</span> <span class="k">import</span> <span class="n">_safe_split</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="k">import</span> <span class="n">_num_samples</span>
<span class="kn">from</span> <span class="nn">WORC.classification.estimators</span> <span class="k">import</span> <span class="n">RankedSVM</span>
<span class="kn">from</span> <span class="nn">WORC.classification</span> <span class="k">import</span> <span class="n">construct_classifier</span> <span class="k">as</span> <span class="n">cc</span>
<span class="kn">from</span> <span class="nn">WORC.classification.metrics</span> <span class="k">import</span> <span class="n">check_multimetric_scoring</span>
<span class="kn">from</span> <span class="nn">WORC.featureprocessing.Relief</span> <span class="k">import</span> <span class="n">SelectMulticlassRelief</span>
<span class="kn">from</span> <span class="nn">WORC.featureprocessing.Imputer</span> <span class="k">import</span> <span class="n">Imputer</span>
<span class="kn">from</span> <span class="nn">WORC.featureprocessing.Scalers</span> <span class="k">import</span> <span class="n">WORCScaler</span>
<span class="kn">from</span> <span class="nn">WORC.featureprocessing.VarianceThreshold</span> <span class="k">import</span> <span class="n">selfeat_variance</span>
<span class="kn">from</span> <span class="nn">WORC.featureprocessing.StatisticalTestThreshold</span> <span class="k">import</span> <span class="n">StatisticalTestThreshold</span>
<span class="kn">from</span> <span class="nn">WORC.featureprocessing.SelectGroups</span> <span class="k">import</span> <span class="n">SelectGroups</span>
<span class="kn">from</span> <span class="nn">WORC.featureprocessing.OneHotEncoderWrapper</span> <span class="k">import</span> <span class="n">OneHotEncoderWrapper</span>
<span class="kn">import</span> <span class="nn">WORC.addexceptions</span> <span class="k">as</span> <span class="nn">ae</span>

<span class="c1"># Specific imports for error management</span>
<span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="k">import</span> <span class="n">LinearDiscriminantAnalysis</span> <span class="k">as</span> <span class="n">LDA</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="k">import</span> <span class="n">LinAlgError</span>


<div class="viewcode-block" id="fit_and_score"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.fitandscore.fit_and_score">[docs]</a><span class="k">def</span> <span class="nf">fit_and_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span>
                  <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span>
                  <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                  <span class="n">return_n_test_samples</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                  <span class="n">return_times</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_parameters</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">return_estimator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">error_score</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                  <span class="n">return_all</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fit an estimator to a dataset and score the performance.</span>

<span class="sd">    The following</span>
<span class="sd">    methods can currently be applied as preprocessing before fitting, in</span>
<span class="sd">    this order:</span>
<span class="sd">    0. Apply OneHotEncoder</span>
<span class="sd">    1. Apply feature imputation</span>
<span class="sd">    2. Select features based on feature type group (e.g. shape, histogram).</span>
<span class="sd">    3. Scale features with e.g. z-scoring.</span>
<span class="sd">    4. Apply feature selection based on variance of feature among patients.</span>
<span class="sd">    5. Univariate statistical testing (e.g. t-test, Wilcoxon).</span>
<span class="sd">    6. Use Relief feature selection.</span>
<span class="sd">    7. Select features based on a fit with a LASSO model.</span>
<span class="sd">    8. Select features using PCA.</span>
<span class="sd">    9. Resampling</span>
<span class="sd">    10. If a SingleLabel classifier is used for a MultiLabel problem,</span>
<span class="sd">        a OneVsRestClassifier is employed around it.</span>

<span class="sd">    All of the steps are optional.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator: sklearn estimator, mandatory</span>
<span class="sd">            Unfitted estimator which will be fit.</span>

<span class="sd">    X: array, mandatory</span>
<span class="sd">            Array containingfor each object (rows) the feature values</span>
<span class="sd">            (1st Column) and the associated feature label (2nd Column).</span>

<span class="sd">    y: list(?), mandatory</span>
<span class="sd">            List containing the labels of the objects.</span>

<span class="sd">    scorer: sklearn scorer, mandatory</span>
<span class="sd">            Function used as optimization criterion for the hyperparamater optimization.</span>

<span class="sd">    train: list, mandatory</span>
<span class="sd">            Indices of the objects to be used as training set.</span>

<span class="sd">    test: list, mandatory</span>
<span class="sd">            Indices of the objects to be used as testing set.</span>

<span class="sd">    parameters: dictionary, mandatory</span>
<span class="sd">            Contains the settings used for the above preprocessing functions</span>
<span class="sd">            and the fitting. TODO: Create a default object and show the</span>
<span class="sd">            fields.</span>

<span class="sd">    fit_params:dictionary, default None</span>
<span class="sd">            Parameters supplied to the estimator for fitting. See the SKlearn</span>
<span class="sd">            site for the parameters of the estimators.</span>

<span class="sd">    return_train_score: boolean, default True</span>
<span class="sd">            Save the training score to the final SearchCV object.</span>

<span class="sd">    return_n_test_samples: boolean, default True</span>
<span class="sd">            Save the number of times each sample was used in the test set</span>
<span class="sd">            to the final SearchCV object.</span>

<span class="sd">    return_times: boolean, default True</span>
<span class="sd">            Save the time spend for each fit to the final SearchCV object.</span>

<span class="sd">    return_parameters: boolean, default True</span>
<span class="sd">            Return the parameters used in the final fit to the final SearchCV</span>
<span class="sd">            object.</span>

<span class="sd">    return_estimator : bool, default=False</span>
<span class="sd">        Whether to return the fitted estimator.</span>

<span class="sd">    error_score: numeric or &quot;raise&quot; by default</span>
<span class="sd">            Value to assign to the score if an error occurs in estimator</span>
<span class="sd">            fitting. If set to &quot;raise&quot;, the error is raised. If a numeric</span>
<span class="sd">            value is given, FitFailedWarning is raised. This parameter</span>
<span class="sd">            does not affect the refit step, which will always raise the error.</span>

<span class="sd">    verbose: boolean, default=True</span>
<span class="sd">            If True, print intermediate progress to command line. Warnings are</span>
<span class="sd">            always printed.</span>

<span class="sd">    return_all: boolean, default=True</span>
<span class="sd">            If False, only the ret object containing the performance will be</span>
<span class="sd">            returned. If True, the ret object plus all fitted objects will be</span>
<span class="sd">            returned.</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">    Depending on the return_all input parameter, either only ret or all objects</span>
<span class="sd">    below are returned.</span>

<span class="sd">    ret: list</span>
<span class="sd">        Contains optionally the train_scores and the test_scores,</span>
<span class="sd">        fit_time, score_time, parameters_est</span>
<span class="sd">        and parameters_all.</span>

<span class="sd">    GroupSel: WORC GroupSel Object</span>
<span class="sd">        Either None if the groupwise feature selection is not used, or</span>
<span class="sd">        the fitted object.</span>

<span class="sd">    VarSel: WORC VarSel Object</span>
<span class="sd">        Either None if the variance threshold feature selection is not used, or</span>
<span class="sd">        the fitted object.</span>

<span class="sd">    SelectModel: WORC SelectModel Object</span>
<span class="sd">        Either None if the feature selection based on a fittd model is not</span>
<span class="sd">        used, or the fitted object.</span>

<span class="sd">    feature_labels: list</span>
<span class="sd">        Labels of the features. Only one list is returned, not one per</span>
<span class="sd">        feature object, as we assume all samples have the same feature names.</span>

<span class="sd">    scaler: scaler object</span>
<span class="sd">        Either None if feature scaling is not used, or</span>
<span class="sd">        the fitted object.</span>

<span class="sd">    encoder: WORC Encoder Object</span>
<span class="sd">        Either None if feature OneHotEncoding is not used, or</span>
<span class="sd">        the fitted object.</span>

<span class="sd">    imputer: WORC Imputater Object</span>
<span class="sd">        Either None if feature imputation is not used, or</span>
<span class="sd">        the fitted object.</span>

<span class="sd">    pca: WORC PCA Object</span>
<span class="sd">        Either None if PCA based feature selection is not used, or</span>
<span class="sd">        the fitted object.</span>

<span class="sd">    StatisticalSel: WORC StatisticalSel Object</span>
<span class="sd">        Either None if the statistical test feature selection is not used, or</span>
<span class="sd">        the fitted object.</span>

<span class="sd">    ReliefSel: WORC ReliefSel Object</span>
<span class="sd">        Either None if the RELIEF feature selection is not used, or</span>
<span class="sd">        the fitted object.</span>

<span class="sd">    Sampler: WORC ObjectSampler Object</span>
<span class="sd">        Either None if no resampling is used, or an ObjectSampler object</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># We copy the parameter object so we can alter it and keep the original</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;#######################################&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Starting fit and score of new workflow.&#39;</span><span class="p">)</span>
    <span class="n">para_estimator</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">cc</span><span class="o">.</span><span class="n">construct_classifier</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>

    <span class="c1"># Check the scorer</span>
    <span class="n">scorers</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">check_multimetric_scoring</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>

    <span class="n">para_estimator</span> <span class="o">=</span> <span class="n">delete_cc_para</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>

    <span class="c1"># Get random seed from parameters</span>
    <span class="n">random_seed</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;random_seed&#39;</span><span class="p">]</span>
    <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;random_seed&#39;</span><span class="p">]</span>

    <span class="c1"># X is a tuple: split in two arrays</span>
    <span class="n">feature_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
    <span class="n">feature_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>

    <span class="c1"># Split in train and testing</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">feature_values</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
    <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">feature_values</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
    <span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>

    <span class="c1"># Set some defaults for if a part fails and we return a dummy</span>
    <span class="n">fit_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">score_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">imputer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">GroupSel</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">SelectModel</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">StatisticalSel</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">VarSel</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">ReliefSel</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scorers</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">test_scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">scorers</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
            <span class="n">train_scores</span> <span class="o">=</span> <span class="n">test_scores</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">error_score</span>
        <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
            <span class="n">train_scores</span> <span class="o">=</span> <span class="n">error_score</span>

    <span class="c1"># Initiate dummy return object for when fit and scoring failes: sklearn defaults</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">]</span> <span class="k">if</span> <span class="n">return_train_score</span> <span class="k">else</span> <span class="p">[</span><span class="n">test_scores</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">return_n_test_samples</span><span class="p">:</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">return_times</span><span class="p">:</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">fit_time</span><span class="p">,</span> <span class="n">score_time</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">return_parameters</span><span class="p">:</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_estimator</span><span class="p">:</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>

    <span class="c1"># Additional to sklearn defaults: return all parameters</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>

    <span class="c1"># ------------------------------------------------------------------------</span>
    <span class="c1"># OneHotEncoder</span>
    <span class="k">if</span> <span class="s1">&#39;OneHotEncoding&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;OneHotEncoding&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;True&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Applying OneHotEncoding, will ignore unknowns.&#39;</span><span class="p">)</span>
            <span class="n">feature_labels_tofit</span> <span class="o">=</span>\
                <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;OneHotEncoding_feature_labels_tofit&#39;</span><span class="p">]</span>
            <span class="n">encoder</span> <span class="o">=</span>\
                <span class="n">OneHotEncoderWrapper</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span>
                                     <span class="n">feature_labels_tofit</span><span class="o">=</span><span class="n">feature_labels_tofit</span><span class="p">,</span>
                                     <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
            <span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Encoder is fitted</span>
                <span class="n">feature_labels</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">encoded_feature_labels</span>
                <span class="n">X_train</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
                <span class="n">X_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;OneHotEncoding&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;OneHotEncoding_feature_labels_tofit&#39;</span><span class="p">]</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">encoder</span>

    <span class="c1"># ------------------------------------------------------------------------</span>
    <span class="c1"># Feature imputation</span>
    <span class="k">if</span> <span class="s1">&#39;Imputation&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Imputation&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;True&#39;</span><span class="p">:</span>
            <span class="n">imp_type</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ImputationMethod&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Imputing NaN with </span><span class="si">{imp_type}</span><span class="s1">.&#39;</span><span class="p">)</span>
            <span class="n">imp_nn</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ImputationNeighbours&#39;</span><span class="p">]</span>

            <span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">missing_values</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">imp_type</span><span class="p">,</span>
                              <span class="n">n_neighbors</span><span class="o">=</span><span class="n">imp_nn</span><span class="p">)</span>
            <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

            <span class="n">original_shape</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">X_train</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
            <span class="n">imputed_shape</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">original_shape</span> <span class="o">!=</span> <span class="n">imputed_shape</span><span class="p">:</span>
                <span class="n">removed_features</span> <span class="o">=</span> <span class="n">original_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">imputed_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">raise</span> <span class="n">ae</span><span class="o">.</span><span class="n">WORCValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Several features (</span><span class="si">{removed_features}</span><span class="s1">) were np.NaN for all objects. Hence, imputation was not possible. Either make sure this is correct and turn of imputation, or correct the feature.&#39;</span><span class="p">)</span>

        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Imputation&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ImputationMethod&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ImputationNeighbours&#39;</span><span class="p">]</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">imputer</span>

    <span class="c1"># Remove any NaN feature values if these are still left after imputation</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">replacenan</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">feature_labels</span><span class="o">=</span><span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">replacenan</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">feature_labels</span><span class="o">=</span><span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># ------------------------------------------------------------------------</span>
    <span class="c1"># Groupwise feature selection</span>
    <span class="k">if</span> <span class="s1">&#39;SelectGroups&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Selecting groups of features.&quot;</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectGroups&#39;</span><span class="p">]</span>
        <span class="c1"># TODO: more elegant way to solve this</span>
        <span class="n">feature_groups</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;shape_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;histogram_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;orientation_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_gabor_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_glcm_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_gldm_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_glcmms_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_glrlm_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_glszm_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_gldzm_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_ngtdm_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_ngldm_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;texture_lbp_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;dicom_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;semantic_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;coliage_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;vessel_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;phase_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;fractal_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;location_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;rgrd_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;original_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;wavelet_features&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;log_features&#39;</span><span class="p">]</span>

        <span class="c1"># First take out the toolbox selection, which is a list</span>
        <span class="n">toolboxes</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;toolbox&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;toolbox&#39;</span><span class="p">]</span>

        <span class="c1"># Check per feature group if the parameter is present</span>
        <span class="n">parameters_featsel</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">feature_groups</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">group</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="p">:</span>
                <span class="c1"># Default: do use the group, except for texture features</span>
                <span class="k">if</span> <span class="n">group</span> <span class="o">==</span> <span class="s1">&#39;texture_features&#39;</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="s1">&#39;False&#39;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="n">group</span><span class="p">]</span>
                <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="n">group</span><span class="p">]</span>

            <span class="n">parameters_featsel</span><span class="p">[</span><span class="n">group</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="c1"># Fit groupwise feature selection object</span>
        <span class="n">GroupSel</span> <span class="o">=</span> <span class="n">SelectGroups</span><span class="p">(</span><span class="n">parameters</span><span class="o">=</span><span class="n">parameters_featsel</span><span class="p">,</span>
                                <span class="n">toolboxes</span><span class="o">=</span><span class="n">toolboxes</span><span class="p">)</span>
        <span class="n">GroupSel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Original Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>

        <span class="c1"># Transform all objectd accordingly</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">GroupSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">GroupSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> New Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
        <span class="n">feature_labels</span> <span class="o">=</span> <span class="n">GroupSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">feature_labels</span><span class="p">)</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">GroupSel</span>

    <span class="c1"># Check whether there are any features left</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># TODO: Make a specific WORC exception for this warning.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WARNING]: No features are selected! Probably all feature groups were set to False. Parameters:&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>

        <span class="c1"># Delete the non-used fields</span>
        <span class="n">para_estimator</span> <span class="o">=</span> <span class="n">delete_nonestimator_parameters</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ret</span>

    <span class="c1"># ------------------------------------------------------------------------</span>
    <span class="c1"># Feature scaling</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;FeatureScaling&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;None&#39;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Fitting scaler and transforming features, method &#39;</span> <span class="o">+</span>
              <span class="n">f</span><span class="s1">&#39;</span><span class="si">{para_estimator[&quot;FeatureScaling&quot;]}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="n">scaling_method</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;FeatureScaling&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">scaling_method</span> <span class="o">==</span> <span class="s1">&#39;None&#39;</span><span class="p">:</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">skip_features</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;FeatureScaling_skip_features&#39;</span><span class="p">]</span>
        <span class="n">n_skip_feat</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">e</span> <span class="ow">in</span> <span class="n">i</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">skip_features</span><span class="p">)])</span>
        <span class="k">if</span> <span class="n">n_skip_feat</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="c1"># Don&#39;t need to scale any features</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WORC Warning] Skipping scaling, only skip features selected.&#39;</span><span class="p">)</span>
            <span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scaler</span> <span class="o">=</span> <span class="n">WORCScaler</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">scaling_method</span><span class="p">,</span> <span class="n">skip_features</span><span class="o">=</span><span class="n">skip_features</span><span class="p">)</span>
            <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;FeatureScaling&#39;</span><span class="p">]</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">scaler</span>

    <span class="c1"># --------------------------------------------------------------------</span>
    <span class="c1"># Feature selection based on variance</span>
    <span class="k">if</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Featsel_Variance&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;True&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Selecting features based on variance.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Original Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">,</span> <span class="n">VarSel</span> <span class="o">=</span>\
                <span class="n">selfeat_variance</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">)</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">VarSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WARNING]: No features meet the selected Variance threshold! Skipping selection.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> New Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>

    <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Featsel_Variance&#39;</span><span class="p">]</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">VarSel</span>

    <span class="c1"># Check whether there are any features left</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># TODO: Make a specific WORC exception for this warning.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WARNING]: No features are selected! Probably your features have too little variance. Parameters:&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="n">para_estimator</span> <span class="o">=</span> <span class="n">delete_nonestimator_parameters</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ret</span>

    <span class="c1"># --------------------------------------------------------------------</span>
    <span class="c1"># Relief feature selection, possibly multi classself.</span>
    <span class="c1"># Needs to be done after scaling!</span>
    <span class="c1"># para_estimator[&#39;ReliefUse&#39;] = &#39;True&#39;</span>
    <span class="k">if</span> <span class="s1">&#39;ReliefUse&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefUse&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;True&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Selecting features using relief.&quot;</span><span class="p">)</span>

            <span class="c1"># Get parameters from para_estimator</span>
            <span class="n">n_neighbours</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefNN&#39;</span><span class="p">]</span>
            <span class="n">sample_size</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefSampleSize&#39;</span><span class="p">]</span>
            <span class="n">distance_p</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefDistanceP&#39;</span><span class="p">]</span>
            <span class="n">numf</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefNumFeatures&#39;</span><span class="p">]</span>

            <span class="c1"># Fit RELIEF object</span>
            <span class="n">ReliefSel</span> <span class="o">=</span> <span class="n">SelectMulticlassRelief</span><span class="p">(</span><span class="n">n_neighbours</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span>
                                               <span class="n">sample_size</span><span class="o">=</span><span class="n">sample_size</span><span class="p">,</span>
                                               <span class="n">distance_p</span><span class="o">=</span><span class="n">distance_p</span><span class="p">,</span>
                                               <span class="n">numf</span><span class="o">=</span><span class="n">numf</span><span class="p">,</span>
                                               <span class="n">random_state</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
            <span class="n">ReliefSel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Original Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>

            <span class="c1"># Transform all objects accordingly</span>
            <span class="n">X_train</span> <span class="o">=</span> <span class="n">ReliefSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">ReliefSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> New Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
            <span class="n">feature_labels</span> <span class="o">=</span> <span class="n">ReliefSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">feature_labels</span><span class="p">)</span>

        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefUse&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefNN&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefSampleSize&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefDistanceP&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;ReliefNumFeatures&#39;</span><span class="p">]</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">ReliefSel</span>

    <span class="c1"># Check whether there are any features left</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># TODO: Make a specific WORC exception for this warning.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WARNING]: No features are selected! Probably RELIEF could not properly select features. Parameters:&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="n">para_estimator</span> <span class="o">=</span> <span class="n">delete_nonestimator_parameters</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ret</span>

    <span class="c1"># ------------------------------------------------------------------------</span>
    <span class="c1"># Perform feature selection using a model</span>
    <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span>
    <span class="k">if</span> <span class="s1">&#39;SelectFromModel&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;True&#39;</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_estimator&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Selecting features using model </span><span class="si">{model}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;Lasso&#39;</span><span class="p">:</span>
            <span class="c1"># Use lasso model for feature selection</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_lasso_alpha&#39;</span><span class="p">]</span>
            <span class="n">selectestimator</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;LR&#39;</span><span class="p">:</span>
            <span class="c1"># Use logistic regression model for feature selection</span>
            <span class="n">selectestimator</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

        <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;RF&#39;</span><span class="p">:</span>
            <span class="c1"># Use random forest model for feature selection</span>
            <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_n_trees&#39;</span><span class="p">]</span>
            <span class="n">selectestimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ae</span><span class="o">.</span><span class="n">WORCKeyError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Model </span><span class="si">{model}</span><span class="s1"> is not known for SelectFromModel. Use Lasso, LR, or RF.&#39;</span><span class="p">)</span>

        <span class="c1"># Prefit model</span>
        <span class="n">selectestimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Use fit to select optimal features</span>
        <span class="n">SelectModel</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">selectestimator</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Original Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>

        <span class="n">X_train_temp</span> <span class="o">=</span> <span class="n">SelectModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train_temp</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WORC WARNING]: No features are selected! Probably your data is too noisy or the selection too strict. Skipping SelectFromModel.&#39;</span><span class="p">)</span>
            <span class="n">SelectModel</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;SelectFromModel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;False&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_train</span> <span class="o">=</span> <span class="n">SelectModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">SelectModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="n">feature_labels</span> <span class="o">=</span> <span class="n">SelectModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">feature_labels</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> New Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>

    <span class="k">if</span> <span class="s1">&#39;SelectFromModel&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_lasso_alpha&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_estimator&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_n_trees&#39;</span><span class="p">]</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">SelectModel</span>

    <span class="c1"># Check whether there are any features left</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># TODO: Make a specific WORC exception for this warning.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WARNING]: No features are selected! Probably SelectFromModel could not properly select features. Parameters:&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="n">para_estimator</span> <span class="o">=</span> <span class="n">delete_nonestimator_parameters</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ret</span>

    <span class="c1"># ----------------------------------------------------------------</span>
    <span class="c1"># PCA dimensionality reduction</span>
    <span class="c1"># Principle Component Analysis</span>
    <span class="k">if</span> <span class="s1">&#39;UsePCA&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;UsePCA&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;True&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fitting PCA&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Original Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
        <span class="k">if</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;PCAType&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;95variance&#39;</span><span class="p">:</span>
            <span class="c1"># Select first X components that describe 95 percent of the explained variance</span>
            <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="n">LinAlgError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;[WARNING]: skipping this setting due to PCA Error: </span><span class="si">{e}</span><span class="s1">.&#39;</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">ret</span>

            <span class="n">evariance</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
            <span class="n">num</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="nb">sum</span> <span class="o">&lt;</span> <span class="mf">0.95</span><span class="p">:</span>
                <span class="nb">sum</span> <span class="o">+=</span> <span class="n">evariance</span><span class="p">[</span><span class="n">num</span><span class="p">]</span>
                <span class="n">num</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Make a PCA based on the determined amound of components</span>
            <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">num</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="n">LinAlgError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;[WARNING]: skipping this setting due to PCA Error: </span><span class="si">{e}</span><span class="s1">.&#39;</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">ret</span>

            <span class="n">X_train</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Assume a fixed number of components: cannot be larger than</span>
            <span class="c1"># n_samples</span>
            <span class="n">n_components</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;PCAType&#39;</span><span class="p">]))</span>

            <span class="k">if</span> <span class="n">n_components</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;[WORC WARNING] PCA n_components (</span><span class="si">{n_components}</span><span class="s2">)&gt; n_features ({len(X_train[0])}): skipping PCA.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
                <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
                <span class="n">X_train</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
                <span class="n">X_test</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> New Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">pca</span>

    <span class="k">if</span> <span class="s1">&#39;UsePCA&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;UsePCA&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;PCAType&#39;</span><span class="p">]</span>

    <span class="c1"># --------------------------------------------------------------------</span>
    <span class="c1"># Feature selection based on a statistical test</span>
    <span class="k">if</span> <span class="s1">&#39;StatisticalTestUse&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;StatisticalTestUse&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;True&#39;</span><span class="p">:</span>
            <span class="n">metric</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;StatisticalTestMetric&#39;</span><span class="p">]</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;StatisticalTestThreshold&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Selecting features based on statistical test. Method </span><span class="si">{metric}</span><span class="s2">, threshold {round(threshold, 5)}.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Original Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>

            <span class="n">StatisticalSel</span> <span class="o">=</span> <span class="n">StatisticalTestThreshold</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
                                                      <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>

            <span class="n">StatisticalSel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">X_train_temp</span> <span class="o">=</span> <span class="n">StatisticalSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train_temp</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WORC WARNING]: No features are selected! Probably your statistical test feature selection was too strict. Skipping thresholding.&#39;</span><span class="p">)</span>
                <span class="n">StatisticalSel</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;StatisticalTestUse&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;False&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X_train</span> <span class="o">=</span> <span class="n">StatisticalSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
                <span class="n">X_test</span> <span class="o">=</span> <span class="n">StatisticalSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
                <span class="n">feature_labels</span> <span class="o">=</span> <span class="n">StatisticalSel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">feature_labels</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> New Length: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>

        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;StatisticalTestUse&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;StatisticalTestMetric&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;StatisticalTestThreshold&#39;</span><span class="p">]</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">StatisticalSel</span>

    <span class="c1"># ------------------------------------------------------------------------</span>
    <span class="c1"># Use object resampling</span>
    <span class="k">if</span> <span class="s1">&#39;Resampling_Use&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_Use&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;True&#39;</span><span class="p">:</span>

            <span class="c1"># Determine our starting balance</span>
            <span class="n">pos_initial</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
            <span class="n">neg_initial</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">-</span> <span class="n">pos_initial</span><span class="p">)</span>
            <span class="n">len_in</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>

            <span class="c1"># Fit ObjectSampler and transform dataset</span>
            <span class="c1"># NOTE: need to save random state for this one as well!</span>
            <span class="n">Sampler</span> <span class="o">=</span>\
                <span class="n">ObjectSampler</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_Method&#39;</span><span class="p">],</span>
                              <span class="n">sampling_strategy</span><span class="o">=</span><span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_sampling_strategy&#39;</span><span class="p">],</span>
                              <span class="n">n_jobs</span><span class="o">=</span><span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_n_cores&#39;</span><span class="p">],</span>
                              <span class="n">n_neighbors</span><span class="o">=</span><span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_n_neighbors&#39;</span><span class="p">],</span>
                              <span class="n">k_neighbors</span><span class="o">=</span><span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_k_neighbors&#39;</span><span class="p">],</span>
                              <span class="n">threshold_cleaning</span><span class="o">=</span><span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_threshold_cleaning&#39;</span><span class="p">],</span>
                              <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="n">Sampler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
                <span class="n">X_train_temp</span><span class="p">,</span> <span class="n">y_train_temp</span> <span class="o">=</span> <span class="n">Sampler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

            <span class="k">except</span> <span class="n">ae</span><span class="o">.</span><span class="n">WORCValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">message</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[WORC WARNING] Skipping resampling: &#39;</span> <span class="o">+</span> <span class="n">message</span><span class="p">)</span>
                <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_Use&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;False&#39;</span>

            <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="s1">&#39;ADASYN is not suited for this specific dataset. Use SMOTE instead.&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                    <span class="c1"># Seldomly occurs, therefore return performance dummy</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;[WARNING]: </span><span class="si">{e}</span><span class="s1">. Returning dummies. Parameters: &#39;</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
                    <span class="n">para_estimator</span> <span class="o">=</span> <span class="n">delete_nonestimator_parameters</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">ret</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">e</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pos</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_train_temp</span><span class="p">))</span>
                <span class="n">neg</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train_temp</span><span class="p">)</span> <span class="o">-</span> <span class="n">pos</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">pos</span> <span class="o">&lt;</span> <span class="mi">10</span> <span class="ow">or</span> <span class="n">neg</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;[WORC WARNING] Skipping resampling: to few objects returned in one or both classes (pos: </span><span class="si">{pos}</span><span class="s1">, neg: </span><span class="si">{neg}</span><span class="s1">).&#39;</span><span class="p">)</span>
                    <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_Use&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;False&#39;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_temp</span>
                    <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train_temp</span>

                    <span class="c1"># Notify the user what the resampling did</span>
                    <span class="n">pos</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
                    <span class="n">neg</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">-</span> <span class="n">pos</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="n">message</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;Resampling from </span><span class="si">{len_in}</span><span class="s2"> (</span><span class="si">{pos_initial}</span><span class="s2"> pos,&quot;</span> <span class="o">+</span>\
                                  <span class="n">f</span><span class="s2">&quot; </span><span class="si">{neg_initial}</span><span class="s2"> neg) to {len(y_train)} (</span><span class="si">{pos}</span><span class="s2"> pos, </span><span class="si">{neg}</span><span class="s2"> neg) patients.&quot;</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

                    <span class="c1"># Also reset train and test indices</span>
                    <span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
                    <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>

        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_Use&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_Method&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_sampling_strategy&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_n_neighbors&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_k_neighbors&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_threshold_cleaning&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Resampling_n_cores&#39;</span><span class="p">]</span>

    <span class="c1"># Delete the object if we do not need to return it</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">Sampler</span>

    <span class="c1"># ----------------------------------------------------------------</span>
    <span class="c1"># Fitting and scoring</span>
    <span class="c1"># Only when using fastr this is an entry</span>
    <span class="k">if</span> <span class="s1">&#39;Number&#39;</span> <span class="ow">in</span> <span class="n">para_estimator</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">para_estimator</span><span class="p">[</span><span class="s1">&#39;Number&#39;</span><span class="p">]</span>

    <span class="c1"># For certainty, we delete all parameters again</span>
    <span class="n">para_estimator</span> <span class="o">=</span> <span class="n">delete_nonestimator_parameters</span><span class="p">(</span><span class="n">para_estimator</span><span class="p">)</span>

    <span class="c1"># NOTE: This just has to go to the construct classifier function,</span>
    <span class="c1"># although it is more convenient here due to the hyperparameter search</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
        <span class="n">labellength</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">labellength</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="n">labellength</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">labellength</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">RankedSVM</span><span class="p">,</span>
                                                   <span class="n">RandomForestClassifier</span><span class="p">]:</span>
        <span class="c1"># Multiclass, hence employ a multiclass classifier for e.g. SVM, LR</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">para_estimator</span><span class="p">)</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Fitting ML method: </span><span class="si">{parameters[&#39;classifiers&#39;]}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="c1"># Recombine feature values and label for train and test set</span>
    <span class="n">feature_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">para_estimator</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">_fit_and_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">feature_values</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                             <span class="n">scorers</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span>
                             <span class="n">test</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span>
                             <span class="n">para_estimator</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">,</span>
                             <span class="n">return_train_score</span><span class="o">=</span><span class="n">return_train_score</span><span class="p">,</span>
                             <span class="n">return_parameters</span><span class="o">=</span><span class="n">return_parameters</span><span class="p">,</span>
                             <span class="n">return_n_test_samples</span><span class="o">=</span><span class="n">return_n_test_samples</span><span class="p">,</span>
                             <span class="n">return_times</span><span class="o">=</span><span class="n">return_times</span><span class="p">,</span>
                             <span class="n">return_estimator</span><span class="o">=</span><span class="n">return_estimator</span><span class="p">,</span>
                             <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="n">LinAlgError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span> <span class="o">==</span> <span class="n">LDA</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;[WARNING]: skipping this setting due to LDA Error: </span><span class="si">{e}</span><span class="s1">.&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">ret</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">e</span>

    <span class="c1"># Add original parameters to return object</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">GroupSel</span><span class="p">,</span> <span class="n">VarSel</span><span class="p">,</span> <span class="n">SelectModel</span><span class="p">,</span> <span class="n">feature_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">imputer</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">StatisticalSel</span><span class="p">,</span> <span class="n">ReliefSel</span><span class="p">,</span> <span class="n">Sampler</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ret</span></div>


<div class="viewcode-block" id="delete_nonestimator_parameters"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.fitandscore.delete_nonestimator_parameters">[docs]</a><span class="k">def</span> <span class="nf">delete_nonestimator_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Delete non-estimator parameters.</span>

<span class="sd">    Delete all parameters in a parameter dictionary that are not used for the</span>
<span class="sd">    actual estimator.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;Number&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Number&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;UsePCA&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;UsePCA&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;PCAType&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;ReliefUse&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ReliefUse&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ReliefNN&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ReliefSampleSize&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ReliefDistanceP&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ReliefNumFeatures&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;OneHotEncoding&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;OneHotEncoding&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;OneHotEncoding_feature_labels_tofit&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;Imputation&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Imputation&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ImputationMethod&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ImputationNeighbours&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;SelectFromModel&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;SelectFromModel&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_lasso_alpha&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_estimator&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;SelectFromModel_n_trees&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;Featsel_Variance&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Featsel_Variance&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;FeatPreProcess&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;FeatPreProcess&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;FeatureScaling&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;FeatureScaling&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;StatisticalTestUse&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;StatisticalTestUse&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;StatisticalTestMetric&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;StatisticalTestThreshold&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;Resampling_Use&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_Use&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_Method&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_sampling_strategy&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_n_neighbors&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_k_neighbors&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_threshold_cleaning&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;Resampling_n_cores&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;random_seed&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;random_seed&#39;</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">parameters</span></div>


<div class="viewcode-block" id="replacenan"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.fitandscore.replacenan">[docs]</a><span class="k">def</span> <span class="nf">replacenan</span><span class="p">(</span><span class="n">image_features</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">feature_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Replace the NaNs in an image feature matrix.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">image_features_temp</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">pnum</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">image_features_temp</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">fnum</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">feature_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;[WORC WARNING] NaN found, patient </span><span class="si">{pnum}</span><span class="s2">, label </span><span class="si">{feature_labels[fnum]}</span><span class="s2">. Replacing with zero.&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;[WORC WARNING] NaN found, patient </span><span class="si">{pnum}</span><span class="s2">, label </span><span class="si">{fnum}</span><span class="s2">. Replacing with zero.&quot;</span><span class="p">)</span>
                <span class="c1"># Note: X is a list of lists, hence we cannot index the element directly</span>
                <span class="n">image_features_temp</span><span class="p">[</span><span class="n">pnum</span><span class="p">,</span> <span class="n">fnum</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="n">image_features_temp</span></div>


<div class="viewcode-block" id="delete_cc_para"><a class="viewcode-back" href="../../../autogen/WORC.classification.html#WORC.classification.fitandscore.delete_cc_para">[docs]</a><span class="k">def</span> <span class="nf">delete_cc_para</span><span class="p">(</span><span class="n">para</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Delete all parameters that are involved in classifier construction.&quot;&quot;&quot;</span>
    <span class="n">deletekeys</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;classifiers&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;max_iter&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SVMKernel&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SVMC&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SVMdegree&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SVMcoef0&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SVMgamma&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;RFn_estimators&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;RFmin_samples_split&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;RFmax_depth&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;LRpenalty&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;LRC&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;LDA_solver&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;LDA_shrinkage&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;QDA_reg_param&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;ElasticNet_alpha&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;ElasticNet_l1_ratio&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SGD_alpha&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SGD_l1_ratio&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SGD_loss&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;SGD_penalty&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;CNB_alpha&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;AdaBoost_learning_rate&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;AdaBoost_n_estimators&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;XGB_boosting_rounds&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;XGB_max_depth&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;XGB_learning_rate&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;XGB_gamma&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;XGB_min_child_weight&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;XGB_colsample_bytree&#39;</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">deletekeys</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">para</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">del</span> <span class="n">para</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">para</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016 -- 2020, Biomedical Imaging Group Rotterdam, Departments of Medical Informatics and Radiology, Erasmus MC, Rotterdam, The Netherlands

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>